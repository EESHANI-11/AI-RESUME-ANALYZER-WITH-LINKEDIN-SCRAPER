{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'scientist,', 'data', 'engineer,', 'data', 'analyst,', 'machine', 'learning', 'engineer,', 'artificial', 'intelligence', 'engineer']\n"
     ]
    }
   ],
   "source": [
    "user_input_job_title = input('Enter Job Titles (with comma separated):').split()\n",
    "print(user_input_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data%2C%20scientist,%2C%20data%2C%20engineer,%2C%20data%2C%20analyst,%2C%20machine%2C%20learning%2C%20engineer,%2C%20artificial%2C%20intelligence%2C%20engineer\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "for i in user_input_job_title:\n",
    "    x = i.split()\n",
    "    y = '%20'.join(x)\n",
    "    b.append(y)\n",
    "\n",
    "job_title = '%2C%20'.join(b)\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://in.linkedin.com/jobs/search?keywords=data%2C%20scientist,%2C%20data%2C%20engineer,%2C%20data%2C%20analyst,%2C%20machine%2C%20learning%2C%20engineer,%2C%20artificial%2C%20intelligence%2C%20engineer&location=India&locationId=&geoId=102713980&f_TPR=r604800&position=1&pageNum=0\n"
     ]
    }
   ],
   "source": [
    "link = f\"https://in.linkedin.com/jobs/search?keywords={job_title}&location=India&locationId=&geoId=102713980&f_TPR=r604800&position=1&pageNum=0\"\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup webdriver\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(link)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "while c < 5:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "    c += 1\n",
    "\n",
    "    try:\n",
    "        x = driver.find_element(by=By.XPATH, value=\"//button[@aria-label='See more jobs']\")\n",
    "        driver.execute_script('arguments[0].click();', x)\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "        time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Infiniti Research Ltd.', 'Locuz', 'Woundtech', 'WILLWARE TECHNOLOGIES', 'Vinfinity Immigration (Official Page)', 'Truelancer.com', 'SAZ India', 'Zupee', 'Walmart Global Tech India', 'HP', 'Cloudside', 'CareerPartner', 'HealthPlix', 'Fluentgrid Limited', 'Walmart Global Tech India', 'intive', 'OneTrust', 'Reltio', 'Shell', 'IQuest Solutions Corporation', 'ScrollTab', 'WILLWARE TECHNOLOGIES', 'CN Solutions', 'AXA XL', 'Aidetic', 'AXA XL', 'Aidetic', 'Squash Apps', 'TIGI HR ®', 'Nice Software Solutions Pvt. Ltd.', 'Ripik.AI', 'Quince', 'Intel Corporation', 'PAGO Analytics', 'Amdocs', 'Muoro', 'Awign', 'Lagnus Private Limited', 'Meeden Labs', 'Jupitice Justice Technologies', 'Response Informatics', 'Mercede', 'Walmart Global Tech India', 'Tamcherry - Zaportiv', 'Quantium', 'PAGO Analytics', 'PAGO Analytics', 'Adobe', 'Sanofi', 'ABB', 'ABB', 'Iron Mountain', 'Berkadia', 'AGCO Corporation', 'NEC Software Solutions', 'PAGO Analytics', 'Esri', 'JPMorgan Chase & Co.', 'Gemini', 'Looper Development Services', 'Gemini', 'PAGO Analytics', 'GlobalFoundries', 'AKS ProTalent', 'Berkadia', 'Greenlight', 'AXA XL', 'TEKGENCE INC', 'V Support Solutions', 'WILLWARE TECHNOLOGIES', 'Quarks', 'Avalara', 'NEC Software Solutions (India)', 'Saras Analytics', 'Indium Software', 'V Support Solutions', 'WILLWARE TECHNOLOGIES', 'Quarks', 'Avalara', 'NEC Software Solutions (India)', 'Saras Analytics', 'Zensar Technologies', 'Indium Software', 'Teksands.ai', 'Bitquery (We are Hiring)', 'PAGO Analytics', 'Dyson', 'Walmart Global Tech India', 'Indegene', 'dentsu', 'ScrollTab', 'Vaishnavi Services', 'Latent bridge', 'Deutsche Bank', 'JPMorgan Chase & Co.', 'Zone IT Solutions', 'Juniper Networks', 'Awign', 'Allica Bank', 'Qualcomm', 'Qualcomm', 'Volvo Group', 'Noble Partners', 'IBM', 'VerSe Innovation', 'Virtusa', 'Comcast', 'JPMorgan Chase & Co.', 'Vaishnavi Services', 'ACL Digital', 'SM NetServ Technologies', 'Vaishnavi Services', 'JPMorgan Chase & Co.', 'Circle K', 'NuStar Technologies', 'Quantium', 'PrismHR', 'AU SMALL FINANCE BANK', 'Changeleaders.in', 'Okta', 'Fractal', 'Vaishnavi Services', 'EPAM Systems', 'Atlassian', 'IBM', 'EPAM Systems', 'IBM', 'Walmart Global Tech India', 'IBM', 'IBM', 'Awign', 'NeoScript', 'Vaishnavi Services', 'Vaishnavi Services', 'IBM', 'IBM', 'Vaishnavi Services', 'IBM', 'Vaishnavi Services', 'IBM', 'IBM', 'Cashgrail', 'Vaishnavi Services', 'Walmart Global Tech India', 'IBM', 'Tech Mahindra (formerly Mahindra Satyam)', 'Think Future Technologies', 'Vaishnavi Services', 'Vaishnavi Services', 'Careator Technologies']\n"
     ]
    }
   ],
   "source": [
    "company_name = []\n",
    "\n",
    "try:\n",
    "    company = driver.find_elements(by=By.CLASS_NAME, value='base-search-card__subtitle')\n",
    "    for i in company:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', 'Machine Learning Engineer', 'Data Scientist', 'Remote ||| Data Scientist 6+Years', 'Data Scientist', 'Data Scientist', 'Data Analyst & Data Scientist (Required Fresher)', 'Data Engineer', 'Staff Data Scientist', 'Data Scientist 3', 'ML Engineer', 'Data Scientist', 'HealthPlix - Junior Data Scientist - Data Visualization Tools', 'Fluentgrid Limited - Data Scientist - Artificial Intelligence/Machine Learning', '(IND) STAFF DATA SCIENTIST', 'Lead AI/ML Engineer', 'Sr Software Engineer - Data Analytics', 'Data Scientist', 'NLP Data Scientist', 'Data Engineer', 'Data Scientist', 'Contractual role: Data Scientist (6+ Years)', 'data scientist', 'Assistant Scientist – Data Science Platform', 'Data Scientist -II', 'Assistant Scientist – Data Science Platform', 'Data Scientist -II', 'AI / ML Engineer', 'Senior Data Engineer', 'Data Engineer', 'Ripik.ai - Data Scientist - Artificial Intelligence', 'Data Scientist 2 - Exp 2-4 Years', 'AI Software Solutions Engineer', 'Data Scientist 2-5 Years Hyderabad(Base Location)(work from home till pandemic) Sep 25,2023 19:51:34', 'Data Scientist', 'Data Scientist - R/Python', 'Data Engineer - SQL/Python', 'Senior AI/ML Engineer', 'Data Engineer', 'Data Scientist - Machine Learning Frameworks', 'Data Scientist - Artificial Intelligence/Machine Learning', 'Data Scientist', 'Staff Data Scientist', 'SAS Data Scientist- FTE', 'IND (New) Data Engineer - wiq', 'Data Scientist 2-5 Years Hyderabad(Base Location)(work from home till pandemic) Sep 26,2023 20:00:17', 'Data Scientist 2-5 Years Hyderabad(Base Location)(work from home till pandemic) Sep 24,2023 19:49:34', 'Sr Data Science Engineer', 'Lead Data Engineer', 'R&D Data Scientist', 'R&D Data Scientist', 'Data Scientist', 'Manager, Data Engineer', 'Data Scientist', 'Data Engineer / Senior Data Engineer - GCP, Bigquery', 'Data Scientist 2-5 Years Hyderabad(Base Location)(work from home till pandemic) Sep 25,2023 19:51:34', 'Product Engineer II - Geospatial Data Science', 'Lead Software Engineer - Java/Python, AWS, ML', 'Staff Data Engineer, Crypto Core', 'Data Engineer', 'Senior Data Engineer, Crypto Core', 'Data Scientist 2-5 Years Hyderabad(Base Location)(work from home till pandemic) Sep 24,2023 19:49:34', 'Data Engineer - Machine Learning/Data Science', 'Data Scientist', 'Senior Data Engineer', 'Data Analytics Engineer', 'Assistant Scientist, Business Data Services', 'Python Data Testing engineer - 5 to 7 years- Bengaluru - Immediate Joiners only', 'ETL and data engineer 5 - 6 Years', 'Contractual Contractual Data Scientist - 6 to 7 years (Remote)', 'Data Engineer - ETL/Data Pipeline', 'Data Engineer', 'Data Engineer / Senior Data Engineer - GCP, Bigquery', 'Interesting Job Opportunity: Saras Analytics - Data Engineer - Python/Data Build Tool', 'Indium Software - Senior Data Engineer - Python/SQL', 'ETL and data engineer 5 - 6 Years', 'Contractual Contractual Data Scientist - 6 to 7 years (Remote)', 'Data Engineer - ETL/Data Pipeline', 'Data Engineer', 'Data Engineer / Senior Data Engineer - GCP, Bigquery', 'Interesting Job Opportunity: Saras Analytics - Data Engineer - Python/Data Build Tool', 'AWS Data engineer', 'Indium Software - Senior Data Engineer - Python/SQL', 'Senior Data Engineer(Snowflake)', 'Data Quality Engineer', 'Data Scientist 2-5 Years Hyderabad(Base Location)(work from home till pandemic) Sep 23,2023 19:54:07', 'Data Ops & Automation Engineer', 'Senior Data Engineer', 'Lead Data Engineer', 'Data Ops Engineer - Software Engineer - Technology', 'Data Engineer (Intern)', 'Machine Learning Engineer', 'Interesting Job Opportunity: LatentBridge - Data Scientist - Python/R', 'GCP Data and CI/CD Engineer', 'Software Engineer III - Data Engineer', 'Big Data Engineer', 'Data Scientist 5', 'Data Engineer', 'Data Engineer', 'AI Model System Software Performance Optimization Engineer', 'AI Model System Software Performance Optimization Engineer', 'Diagnostic Data Engineer', 'Interesting Job Opportunity: Data Scientist - Python/Spark/Hadoop', 'Data Scientist - FinOps', 'Data Engineer', 'Big Data Engineer', 'Data Scientist 2', 'Lead Software Engineer -AWS Big Data', 'Machine Learning Engineer', 'Data Engineer', 'Azure Data Engineer', 'Machine Learning Engineer', 'Data Engineer II', 'Manager, Data Engineer', 'Data bricks Data Engineer', 'IND (New) Senior Data Engineer - wiq', 'Data Engineer', 'Senior Data Engineer', 'Python Data Engineer', 'Staff Software Engineer - Machine Learning', 'GCP Data Engineer (3-8 years)', 'Data Scientist', 'Senior Engineer -Data Quality Automation', 'Data Engineer, Data Engineering', 'Data Scientist: Advanced Analytics', 'Senior Engineer -Data Quality Automation', 'Data Scientist: Advanced Analytics', 'Senior Data Engineer', 'Data Scientist: Advanced Analytics', 'Data Scientist: Advanced Analytics', 'Data Engineer', 'Junior Data Engineer - ETL/Tableau', 'Data Scientist', 'Data Scientist', 'Data Scientist: Advanced Analytics', 'Data Scientist: Artificial Intelligence', 'Machine Learning Engineer', 'Data Scientist: Advanced Analytics', 'Data Scientist', 'Data Scientist: Advanced Analytics', 'Data Scientist: Advanced Analytics', 'Interesting Job Opportunity: Zupee - Data Engineer - ETL/Data Pipeline', 'Machine Learning Engineer', 'Senior Data Engineer', 'Data Scientist - FinOps', 'GCP Developer / GCP Cloud Data engineer', 'Data Engineer (GCP)', 'Data Scientist', 'Data Scientist', 'Data Engineer - SQL/Python']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_title = []\n",
    "\n",
    "try:\n",
    "    title = driver.find_elements(by=By.CLASS_NAME, value='base-search-card__title')\n",
    "    for i in title:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bengaluru, Karnataka, India', 'Hyderabad, Telangana, India', 'Hyderabad, Telangana, India', 'India', 'Greater Hyderabad Area', 'India', 'India', 'Gurugram, Haryana, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Coimbatore, Tamil Nadu, India', 'India', 'Bengaluru, Karnataka, India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Ahmedabad, Gujarat, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'India', 'India', 'Bengaluru, Karnataka, India', 'Gurgaon, Haryana, India', 'Bengaluru North, Karnataka, India', 'Gurgaon, Haryana, India', 'Bengaluru North, Karnataka, India', 'Coimbatore, Tamil Nadu, India', 'India', 'Pune, Maharashtra, India', 'Jharkhand, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Hyderabad, Telangana, India', 'Pune/Pimpri-Chinchwad Area', 'Gurugram, Haryana, India', 'Bengaluru, Karnataka, India', 'Coimbatore, Tamil Nadu, India', 'Bengaluru, Karnataka, India', 'Chandigarh, Chandigarh, India', 'Kolkata, West Bengal, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Chennai, Tamil Nadu, India', 'Hyderabad, Telangana, India', 'Hyderabad, Telangana, India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bengaluru East, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Mumbai, Maharashtra, India', 'Hyderabad, Telangana, India', 'New Delhi, Delhi, India', 'Bengaluru, Karnataka, India', 'Gurgaon, Haryana, India', 'Mumbai, Maharashtra, India', 'Gurgaon, Haryana, India', 'Hyderabad, Telangana, India', 'Bangalore Urban, Karnataka, India', 'India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Gurgaon, Haryana, India', 'Bengaluru, Karnataka, India', 'Coimbatore, Tamil Nadu, India', 'India', 'Gurugram, Haryana, India', 'Pune, Maharashtra, India', 'Mumbai, Maharashtra, India', 'Hyderabad, Telangana, India', 'Hyderabad, Telangana, India', 'Coimbatore, Tamil Nadu, India', 'India', 'Gurugram, Haryana, India', 'Pune, Maharashtra, India', 'Mumbai, Maharashtra, India', 'Hyderabad, Telangana, India', 'Pune/Pimpri-Chinchwad Area', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Hyderabad, Telangana, India', 'Bengaluru East, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bangalore Urban, Karnataka, India', 'Bengaluru, Karnataka, India', 'India', 'Bengaluru, Karnataka, India', 'Noida, Uttar Pradesh, India', 'Pune, Maharashtra, India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bangalore Urban, Karnataka, India', 'Hyderabad, Telangana, India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Bhagawanpur-II, West Bengal, India', 'Bengaluru East, Karnataka, India', 'Bangalore Urban, Karnataka, India', 'Andhra Pradesh, India', 'Chennai, Tamil Nadu, India', 'Bengaluru, Karnataka, India', 'Greater Kolkata Area', 'Bengaluru, Karnataka, India', 'Bengaluru, Karnataka, India', 'Janjgir, Chhattisgarh, India', 'Pune, Maharashtra, India', 'Gurugram, Haryana, India', 'Bengaluru, Karnataka, India', 'Hyderabad, Telangana, India', 'Noida, Uttar Pradesh, India', 'Jaipur, Rajasthan, India', 'Chennai, Tamil Nadu, India', 'Bengaluru, Karnataka, India', 'Pune, Maharashtra, India', 'Rohtak, Haryana, India', 'Hyderabad, Telangana, India', 'Bengaluru, Karnataka, India', 'Bengaluru East, Karnataka, India', 'Pune, Maharashtra, India', 'Bengaluru East, Karnataka, India', 'Bengaluru, Karnataka, India', 'Bengaluru East, Karnataka, India', 'Bengaluru East, Karnataka, India', 'Bengaluru North, Karnataka, India', 'Bengaluru, Karnataka, India', 'Rewari, Haryana, India', 'Ambala, Haryana, India', 'Bengaluru East, Karnataka, India', 'Gurgaon, Haryana, India', 'Kanker, Chhattisgarh, India', 'Bengaluru East, Karnataka, India', 'Ahmedabad, Gujarat, India', 'Bengaluru East, Karnataka, India', 'Bengaluru East, Karnataka, India', 'Gurugram, Haryana, India', 'Nafra, Arunachal Pradesh, India', 'Chennai, Tamil Nadu, India', 'Kochi, Kerala, India', 'Hyderabad, Telangana, India', 'Gurugram, Haryana, India', 'Bharuch, Gujarat, India', 'Mehsana, Gujarat, India', 'Hyderabad, Telangana, India']\n"
     ]
    }
   ],
   "source": [
    "company_location = []\n",
    "\n",
    "try:\n",
    "    location = driver.find_elements(by=By.CLASS_NAME, value='job-search-card__location')\n",
    "    for i in location:\n",
    "        company_location.append(i.text)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(company_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://in.linkedin.com/jobs/view/data-scientist-at-infiniti-research-ltd-3726564577?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=%2FSb1FFS1IXFcj22c3UeaxQ%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-locuz-3730084815?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=TMch8Uife%2FbnZNFfa37r7A%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-woundtech-3729495606?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=BQ9HB494oz2VCMYRREbVbQ%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/remote-data-scientist-6%2Byears-at-willware-technologies-3726561793?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=NNj75SmOm0oPr8TE6o4NLQ%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vinfinity-immigration-official-page-3726565641?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=JJpolfO9D6kcg%2FhzyPH2tQ%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-truelancer-com-3730081516?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=7yXA0cYlnyd%2BOfO0bVv4WA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-analyst-data-scientist-required-fresher-at-saz-india-3726251569?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=4PlMhFszPixI4O%2BLg6OUNQ%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-zupee-3730082796?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=TaU4G0u3MqLgQC0qTO%2F4tw%3D%3D&position=8&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/staff-data-scientist-at-walmart-global-tech-india-3728774476?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=BWrjpLBJ4sJBXueuoJLaYg%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-3-at-hp-3727523150?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=bT0BueibuDU%2BwCU%2FHsGOrQ%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ml-engineer-at-cloudside-3724363831?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=KzBi9SjnNwxDJkoXLO7KOw%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-careerpartner-3728201799?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=bZp748WKAragwOt1T2RdNw%3D%3D&position=12&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/healthplix-junior-data-scientist-data-visualization-tools-at-healthplix-3722419473?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=BSONaKz%2FDcFd1Z56fjWCPA%3D%3D&position=13&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/fluentgrid-limited-data-scientist-artificial-intelligence-machine-learning-at-fluentgrid-limited-3726501146?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=CaQFHukbQk2xcz39G8iuhw%3D%3D&position=14&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ind-staff-data-scientist-at-walmart-global-tech-india-3725815150?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=EvNuzePDOj%2F30R1MHh1I8w%3D%3D&position=15&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/lead-ai-ml-engineer-at-intive-3727534463?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=C8%2BKnLFG%2FQ%2FNZL6u%2FW9wqw%3D%3D&position=16&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/sr-software-engineer-data-analytics-at-onetrust-3674266803?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=y%2Bni2izVtWSbuMycM%2FtkdQ%3D%3D&position=17&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-reltio-3727811560?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=1a5V%2BU3ML4ukLtUv2%2FPssg%3D%3D&position=18&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/nlp-data-scientist-at-shell-3729599743?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=QgB8FMSCB%2B8TanX6prwNjA%3D%3D&position=19&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-iquest-solutions-corporation-3728595303?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=0Re2MpBPSZKXqpL%2FYJhKow%3D%3D&position=20&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-scrolltab-3728019899?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=cYoIRf3jiLUF630yvwqSJw%3D%3D&position=21&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/contractual-role-data-scientist-6%2B-years-at-willware-technologies-3726564720?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=Ycf8Sq%2FM4d5%2BRKt56HRUhQ%3D%3D&position=22&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-cn-solutions-3727011479?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=yF%2BOm86rdfts9TRh3qWOhw%3D%3D&position=23&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/assistant-scientist-%E2%80%93-data-science-platform-at-axa-xl-3726260937?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=gY4v4M2fThEjEMU1z2iopA%3D%3D&position=24&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-ii-at-aidetic-3724368456?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=9HMHykRKqVQx1aoZQMVt0w%3D%3D&position=25&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/assistant-scientist-%E2%80%93-data-science-platform-at-axa-xl-3726260937?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=c4M%2FfUBqiD4QzUgyz%2FRvoQ%3D%3D&position=1&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-ii-at-aidetic-3724368456?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=sP%2Bx5CqHJVRwLVEHHUYKNg%3D%3D&position=2&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ai-ml-engineer-at-squash-apps-3722450794?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=OQmfAzNsy3f5zkoybARxTw%3D%3D&position=3&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-at-tigi-hr-%C2%AE-3726555876?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=Gg%2BqpaBqrMTeEXUKGlhAuw%3D%3D&position=4&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-nice-software-solutions-pvt-ltd-3726560306?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=3am6j1Cn4MVUeK2%2Bh9JVGg%3D%3D&position=5&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ripik-ai-data-scientist-artificial-intelligence-at-ripik-ai-3722415922?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=vgnlwCQ%2BQoo7CFvE%2FvJXCQ%3D%3D&position=6&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-exp-2-4-years-at-quince-3724335910?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=emy4g55W4i24OUo%2BoCOjeQ%3D%3D&position=7&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ai-software-solutions-engineer-at-intel-corporation-3710796953?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=1M3SkcwxsNEDG%2F8p8fJbBA%3D%3D&position=8&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-5-years-hyderabad-base-location-work-from-home-till-pandemic-sep-25-2023-19-51-34-at-pago-analytics-3728255616?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=qyznifZ7MB6b5QmDQKYQTA%3D%3D&position=9&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-amdocs-3724354014?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=60xZWhQO3PJIWlzGgoW7Dw%3D%3D&position=10&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-r-python-at-muoro-3725574231?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=Nib1TnaHnbxrWFvuKJS6Nw%3D%3D&position=11&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-sql-python-at-awign-3725577076?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=oVZkblHk%2F9adbEaUjHH2Eg%3D%3D&position=12&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-ai-ml-engineer-at-lagnus-private-limited-3723306916?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=0Q4FuUNRlUTZDttFqjsC5g%3D%3D&position=13&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-meeden-labs-3726560802?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=zc%2FC53kZBqURrVezmJoqQA%3D%3D&position=14&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-machine-learning-frameworks-at-jupitice-justice-technologies-3722422065?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=Ce3AGPs3JUQPCTdKjNdwRw%3D%3D&position=15&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-artificial-intelligence-machine-learning-at-response-informatics-3721922006?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=2qJGonK4cbR13Zw4gEjohw%3D%3D&position=16&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-mercede-3727503052?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=8aQzm0ALCMTzG77ylQmdGA%3D%3D&position=17&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/staff-data-scientist-at-walmart-global-tech-india-3728957345?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=7SgR0aZfIbOsvtVd2cDMHw%3D%3D&position=18&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/sas-data-scientist-fte-at-tamcherry-zaportiv-3727016964?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=s96tUgekbhA1CoxZyHzMbw%3D%3D&position=19&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ind-new-data-engineer-wiq-at-quantium-3675415506?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=nhuBsEy%2FaUxkNqMx%2FCYwuw%3D%3D&position=20&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-5-years-hyderabad-base-location-work-from-home-till-pandemic-sep-26-2023-20-00-17-at-pago-analytics-3728259304?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=YbqlT3dbCBG7BvJhH3AqOA%3D%3D&position=21&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-5-years-hyderabad-base-location-work-from-home-till-pandemic-sep-24-2023-19-49-34-at-pago-analytics-3728254747?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=q7OrjhYugE541n%2BW5Sy%2FgA%3D%3D&position=22&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/sr-data-science-engineer-at-adobe-3726694558?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=hcwgvhn1krAs98msFnb15w%3D%3D&position=23&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/lead-data-engineer-at-sanofi-3730084286?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=BJzhFo9bcCSI6NduJJNEWA%3D%3D&position=24&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/r-d-data-scientist-at-abb-3713366155?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=K0g0lKCHAQgNFxPvAPlSLw%3D%3D&position=25&pageNum=1&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/r-d-data-scientist-at-abb-3713366155?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=pTcqYpzGQHvXRl%2FO420dxA%3D%3D&position=1&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-iron-mountain-3727599381?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=QOKJrjBGmQ6shPn1fmLyWg%3D%3D&position=2&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/manager-data-engineer-at-berkadia-3727814308?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=EgVqzNhWdywc7yBcNr0ZIg%3D%3D&position=3&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-agco-corporation-3724878929?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=SXHTOS7Eth6uA%2BPbJgWQEQ%3D%3D&position=4&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-senior-data-engineer-gcp-bigquery-at-nec-software-solutions-3728272266?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=KcJzR8hWd8nCGvk6rwfjug%3D%3D&position=5&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-5-years-hyderabad-base-location-work-from-home-till-pandemic-sep-25-2023-19-51-34-at-pago-analytics-3728259185?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=hDp%2FU9tYtB77qTL6lL%2B6vQ%3D%3D&position=6&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/product-engineer-ii-geospatial-data-science-at-esri-3726102463?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=cGdFcqqnGqUkB01zwyNJow%3D%3D&position=7&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/lead-software-engineer-java-python-aws-ml-at-jpmorgan-chase-co-3726557589?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=hnSWhvZVJzYtTNDf5GrZMQ%3D%3D&position=8&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/staff-data-engineer-crypto-core-at-gemini-3730082137?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=TfWa55ShHTyMjkYcrZcTNQ%3D%3D&position=9&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-looper-development-services-3730086232?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=G1bqQ%2BpQ4GoCk2RVL%2BqkWA%3D%3D&position=10&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-crypto-core-at-gemini-3730083113?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=vdPE7nvkVzMftEpOfjQCSA%3D%3D&position=11&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-5-years-hyderabad-base-location-work-from-home-till-pandemic-sep-24-2023-19-49-34-at-pago-analytics-3728253796?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=gP5m8uQVwlfXwNnq4cj2SA%3D%3D&position=12&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-machine-learning-data-science-at-globalfoundries-3696940494?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=usKKLoSe%2FBJ9jNdTLEP16A%3D%3D&position=13&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-aks-protalent-3726244516?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=uARNDGrFDpOG8JAPhwbmMg%3D%3D&position=14&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-at-berkadia-3612402134?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=Ik9knU1szv1Enc2azvfnrA%3D%3D&position=15&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-analytics-engineer-at-greenlight-3727925571?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=JvvhGRsTyEWdPmTr9IzTCA%3D%3D&position=16&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/assistant-scientist-business-data-services-at-axa-xl-3726268052?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=tXFDpYv2K03UMUbLGOxbfQ%3D%3D&position=17&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/python-data-testing-engineer-5-to-7-years-bengaluru-immediate-joiners-only-at-tekgence-inc-3721195039?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=wrc4WVtJLvdLXqpfhULq3w%3D%3D&position=18&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/etl-and-data-engineer-5-6-years-at-v-support-solutions-3726561169?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=9BgVHhdCcZJUhW8v%2BtHK9g%3D%3D&position=19&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/contractual-contractual-data-scientist-6-to-7-years-remote-at-willware-technologies-3726561833?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=cOgDUf85G92q9VuFjeJKqg%3D%3D&position=20&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-etl-data-pipeline-at-quarks-3726294999?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=MKxM64IakDbCwRAwgsZCgw%3D%3D&position=21&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-avalara-3726243886?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=mgIoQXWr9xkI6HxkIMrQ3w%3D%3D&position=22&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-senior-data-engineer-gcp-bigquery-at-nec-software-solutions-india-3728285039?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=RI0JUKjDjxLv3rXMQzPgUw%3D%3D&position=23&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/interesting-job-opportunity-saras-analytics-data-engineer-python-data-build-tool-at-saras-analytics-3721919445?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=g93IEPMZqHUpF5S2tOlk5g%3D%3D&position=24&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/indium-software-senior-data-engineer-python-sql-at-indium-software-3722422070?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=IinF7s9z%2BEqG9gnJlIY5Rw%3D%3D&position=25&pageNum=2&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/etl-and-data-engineer-5-6-years-at-v-support-solutions-3726561169?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=sRJFwELmavuMl59%2FAVeMug%3D%3D&position=1&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/contractual-contractual-data-scientist-6-to-7-years-remote-at-willware-technologies-3726561833?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=p7GdFcsdgkNqMwBRQFeBBQ%3D%3D&position=2&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-etl-data-pipeline-at-quarks-3726294999?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=0ytoH5gA5FfvjOyM6%2FeXhg%3D%3D&position=3&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-avalara-3726243886?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=Vq%2BWodEw42T3fMivEJ8qsg%3D%3D&position=4&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-senior-data-engineer-gcp-bigquery-at-nec-software-solutions-india-3728285039?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=9Ptosae%2BQTzd8X6J5xHTFg%3D%3D&position=5&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/interesting-job-opportunity-saras-analytics-data-engineer-python-data-build-tool-at-saras-analytics-3721919445?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=I4t0bgkdM5W8O8UAxrL6Hg%3D%3D&position=6&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/aws-data-engineer-at-zensar-technologies-3729502786?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=jm3kBiD1aP%2F%2B%2BxnS%2B%2F8qpA%3D%3D&position=7&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/indium-software-senior-data-engineer-python-sql-at-indium-software-3722422070?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=FLuDLeubC4dNsT3itHGZsg%3D%3D&position=8&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-snowflake-at-teksands-ai-3726279436?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=bOCOwK9LLs8bKV0xhbrXMA%3D%3D&position=9&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-quality-engineer-at-bitquery-we-are-hiring-3728798699?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=LY%2FbYetuPoXoOy0UYnL8tQ%3D%3D&position=10&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-5-years-hyderabad-base-location-work-from-home-till-pandemic-sep-23-2023-19-54-07-at-pago-analytics-3726673643?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=enIWJZXzK2WgRPl7ZuriEQ%3D%3D&position=11&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-ops-automation-engineer-at-dyson-3688898551?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=2s8wyRPJLvgmSf8yEU8OtA%3D%3D&position=12&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-at-walmart-global-tech-india-3678826715?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=WUdRFVubBqagRRQsG9uxWw%3D%3D&position=13&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/lead-data-engineer-at-indegene-3725569921?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=A12LIMJuu7gHAAI7EPfZ7g%3D%3D&position=14&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-ops-engineer-software-engineer-technology-at-dentsu-3727697336?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=fgC7QLwd9qbsywLKkRUtWQ%3D%3D&position=15&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-intern-at-scrolltab-3729153707?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=8ztcUPYC1hInINWzc%2FISIg%3D%3D&position=16&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-vaishnavi-services-3726147933?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=5hTB4r%2BNKkNl8FwlkVljgA%3D%3D&position=17&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/interesting-job-opportunity-latentbridge-data-scientist-python-r-at-latent-bridge-3725571777?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=kh95LkVX%2F4GIR7kZm2VASQ%3D%3D&position=18&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/gcp-data-and-ci-cd-engineer-at-deutsche-bank-3729120162?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=eS2gPoyLUEuZJvuFhhMpZQ%3D%3D&position=19&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/software-engineer-iii-data-engineer-at-jpmorgan-chase-co-3726552897?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=EJC7uUGCwYgB9vFyDoRMQg%3D%3D&position=20&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/big-data-engineer-at-zone-it-solutions-3727659781?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=55fxCg0XRk14OoqGgolVeQ%3D%3D&position=21&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-5-at-juniper-networks-3726889797?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=qnFKFFNfBmLPcVbkoVq50w%3D%3D&position=22&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-awign-3725556312?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=kE%2B2qE4uxCRnMlxC6pc0jg%3D%3D&position=23&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-allica-bank-3725424528?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=ONfLOkj7Cy0jG3XzLHvrvg%3D%3D&position=24&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ai-model-system-software-performance-optimization-engineer-at-qualcomm-3728397201?refId=y9lN1ti47uVeP%2BZXmze1Xg%3D%3D&trackingId=e77WEF2iTBTtUOYJmAwmPg%3D%3D&position=25&pageNum=3&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ai-model-system-software-performance-optimization-engineer-at-qualcomm-3728397201?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=5%2FEl3HRpYz587bFiiH5WUg%3D%3D&position=1&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/diagnostic-data-engineer-at-volvo-group-3726626165?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=GbkiJS3Ok0Ar4ocQSOlFFw%3D%3D&position=2&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/interesting-job-opportunity-data-scientist-python-spark-hadoop-at-noble-partners-3726295896?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=TndEAFmovTNkcqzpGoJB5A%3D%3D&position=3&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-finops-at-ibm-3714355012?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=KsGdo1Yji%2Bbui8EWBGKU6g%3D%3D&position=4&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-verse-innovation-3721925794?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=n5i1qBLwCmke%2B9JY3ydIcA%3D%3D&position=5&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/big-data-engineer-at-virtusa-3706462274?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=VCjdbU9t0tyt4KXvXz6EWg%3D%3D&position=6&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-2-at-comcast-3728281618?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=m1TqHLPKb57QzNVuTGgLaw%3D%3D&position=7&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/lead-software-engineer-aws-big-data-at-jpmorgan-chase-co-3726556610?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=zL8cYMz7UhRCvOu%2Fz%2BnqKw%3D%3D&position=8&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-vaishnavi-services-3726147952?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=hhNRXzA9f8hIuvH%2BBUy3mQ%3D%3D&position=9&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-acl-digital-3728556995?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=innIk8z%2Fn9hhwIdrOlyaYQ%3D%3D&position=10&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/azure-data-engineer-at-sm-netserv-technologies-3726570035?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=xjyCYEEp7v1B7IR9DhW58A%3D%3D&position=11&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-vaishnavi-services-3726146910?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=0x6SLU%2F50lhV%2BZrnzKtAig%3D%3D&position=12&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-ii-at-jpmorgan-chase-co-3721987929?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=vyCEH0sybYIcZL9GRKTuRg%3D%3D&position=13&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/manager-data-engineer-at-circle-k-3668400392?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=OUot0EQrxvWWDEokzOXUgQ%3D%3D&position=14&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-bricks-data-engineer-at-nustar-technologies-3727994096?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=x9M3xz%2BTaS3BqlASemsczQ%3D%3D&position=15&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/ind-new-senior-data-engineer-wiq-at-quantium-3675425099?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=%2FRJ68ovqYt7wtzzC6uyqJg%3D%3D&position=16&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-prismhr-3390030674?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=9nMw9Q8UVA4KUxtdimFmUA%3D%3D&position=17&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-at-au-small-finance-bank-3721180334?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=8m97LPJaKp1IlbJLK5QL0w%3D%3D&position=18&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/python-data-engineer-at-changeleaders-in-3727033085?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=8Ashpy%2BYRBKD4jpPh3EbRQ%3D%3D&position=19&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/staff-software-engineer-machine-learning-at-okta-3689265766?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=2%2FdM0w2CW3mmhabnacQ%2FzA%3D%3D&position=20&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/gcp-data-engineer-3-8-years-at-fractal-3725817385?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=GhGeecPPxVMdeT1i6s82Dg%3D%3D&position=21&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vaishnavi-services-3726146913?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=NxvEAgvORXWYDIU6cz3h0A%3D%3D&position=22&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-engineer-data-quality-automation-at-epam-systems-3710665851?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=Ts7v2Ds6xvW8QU4i1WIZQg%3D%3D&position=23&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-data-engineering-at-atlassian-3721188341?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=1o6OdP7zudQqUhZ2T%2BUaEg%3D%3D&position=24&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723327198?refId=b3Tn8XXkorKSqrKU0%2FbHgg%3D%3D&trackingId=u6obTTN3kw2JfSPkPJiC0Q%3D%3D&position=25&pageNum=4&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-engineer-data-quality-automation-at-epam-systems-3710662993?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=2Mqm6GnHy3NqxdCWMsX38Q%3D%3D&position=1&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723329018?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=ZcPiJ8TaO922vUlwNv%2BjiA%3D%3D&position=2&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-at-walmart-global-tech-india-3678826715?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=7AQH7nVpLV23h2pF0n1p8A%3D%3D&position=3&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723328106?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=AJt2Dhn02Rcs6u9fJs1IpQ%3D%3D&position=4&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723326487?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=Cxv3ZCR9ZgamSOxKJM0MBA%3D%3D&position=5&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-at-awign-3727165493?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=9eYGGL7m2tDmVI2g%2Fit74Q%3D%3D&position=6&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/junior-data-engineer-etl-tableau-at-neoscript-3724344682?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=haqfHj8%2FXO64JzYNpR0lTw%3D%3D&position=7&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vaishnavi-services-3726148741?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=MRLkAaqf2dvZynJHYPuEjA%3D%3D&position=8&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vaishnavi-services-3726150428?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=L%2BLHXYdnJcOUZ8yi60SIMg%3D%3D&position=9&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723326488?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=KhfPLVQXUvDzsLwgsXa5rg%3D%3D&position=10&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-artificial-intelligence-at-ibm-3726505030?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=KKLozPaSaxGW0OXcIHPSkw%3D%3D&position=11&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-vaishnavi-services-3726151945?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=%2Fdzt7UYHTF38jTtGh3kUcw%3D%3D&position=12&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723328112?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=HK5oJra25FodG%2BupqMusNA%3D%3D&position=13&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vaishnavi-services-3726148740?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=vFHf3eGTgGGT9cf7c%2B7PNg%3D%3D&position=14&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723324736?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=kFqdA7Owqyucen%2BGNxyNhQ%3D%3D&position=15&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-advanced-analytics-at-ibm-3723323844?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=%2Bo4Ja8MLYcehDAZdk0m22g%3D%3D&position=16&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/interesting-job-opportunity-zupee-data-engineer-etl-data-pipeline-at-cashgrail-3725571784?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=Z6qMWt2k%2Fk9V3g%2BG%2BY3%2BqQ%3D%3D&position=17&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/machine-learning-engineer-at-vaishnavi-services-3726147951?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=O1s8quvdS8VyI9qjw2pi3w%3D%3D&position=18&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/senior-data-engineer-at-walmart-global-tech-india-3729178453?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=eLeTNWz9DCpitR7OCf7EgQ%3D%3D&position=19&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-finops-at-ibm-3714348856?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=TmI%2BjeGtX53btkkfR6mB%2FA%3D%3D&position=20&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/gcp-developer-gcp-cloud-data-engineer-at-tech-mahindra-formerly-mahindra-satyam-3721188976?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=POEUmB5Gx54FQWJpK0Nf5A%3D%3D&position=21&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-gcp-at-think-future-technologies-3727993935?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=YOolvmgFWZs5GUyYGqQIpQ%3D%3D&position=22&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vaishnavi-services-3726151966?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=Pihkf5tNQr2OPJq6LvdCfA%3D%3D&position=23&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-vaishnavi-services-3726146940?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=oW1riyS9A%2BWaUjSe%2B5IatA%3D%3D&position=24&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-engineer-sql-python-at-careator-technologies-3725578043?refId=jIudfohzqkFpvOZ5ZAg4Mw%3D%3D&trackingId=f8NFXVvSUAJ91FN%2Fv9sKTA%3D%3D&position=25&pageNum=5&trk=public_jobs_jserp-result_search-card', 'https://in.linkedin.com/jobs/view/data-scientist-at-infiniti-research-ltd-3726564577?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=%2FSb1FFS1IXFcj22c3UeaxQ%3D%3D&trk=public_jobs_topcard-title']\n"
     ]
    }
   ],
   "source": [
    "job_url = []\n",
    "\n",
    "try:\n",
    "    url = driver.find_elements(by=By.XPATH, value=\"//a[contains(@href, '/jobs/')]\")\n",
    "    url_list = [i.get_attribute('href') for i in url]\n",
    "    for url in url_list:\n",
    "        job_url.append(url)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(job_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Infiniti Research Ltd.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Locuz</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woundtech</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WILLWARE TECHNOLOGIES</td>\n",
       "      <td>Remote ||| Data Scientist 6+Years</td>\n",
       "      <td>India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/remote-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vinfinity Immigration (Official Page)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Greater Hyderabad Area</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Tech Mahindra (formerly Mahindra Satyam)</td>\n",
       "      <td>GCP Developer / GCP Cloud Data engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/gcp-develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Think Future Technologies</td>\n",
       "      <td>Data Engineer (GCP)</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Vaishnavi Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bharuch, Gujarat, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Vaishnavi Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mehsana, Gujarat, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Careator Technologies</td>\n",
       "      <td>Data Engineer - SQL/Python</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Company Name  \\\n",
       "0                      Infiniti Research Ltd.   \n",
       "1                                       Locuz   \n",
       "2                                   Woundtech   \n",
       "3                       WILLWARE TECHNOLOGIES   \n",
       "4       Vinfinity Immigration (Official Page)   \n",
       "..                                        ...   \n",
       "145  Tech Mahindra (formerly Mahindra Satyam)   \n",
       "146                 Think Future Technologies   \n",
       "147                        Vaishnavi Services   \n",
       "148                        Vaishnavi Services   \n",
       "149                     Careator Technologies   \n",
       "\n",
       "                                   Job Title                     Location  \\\n",
       "0                             Data Scientist  Bengaluru, Karnataka, India   \n",
       "1                  Machine Learning Engineer  Hyderabad, Telangana, India   \n",
       "2                             Data Scientist  Hyderabad, Telangana, India   \n",
       "3          Remote ||| Data Scientist 6+Years                        India   \n",
       "4                             Data Scientist       Greater Hyderabad Area   \n",
       "..                                       ...                          ...   \n",
       "145  GCP Developer / GCP Cloud Data engineer  Hyderabad, Telangana, India   \n",
       "146                      Data Engineer (GCP)     Gurugram, Haryana, India   \n",
       "147                           Data Scientist      Bharuch, Gujarat, India   \n",
       "148                           Data Scientist      Mehsana, Gujarat, India   \n",
       "149               Data Engineer - SQL/Python  Hyderabad, Telangana, India   \n",
       "\n",
       "                                           Website URL  \n",
       "0    https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "1    https://in.linkedin.com/jobs/view/machine-lear...  \n",
       "2    https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "3    https://in.linkedin.com/jobs/view/remote-data-...  \n",
       "4    https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "..                                                 ...  \n",
       "145  https://in.linkedin.com/jobs/view/gcp-develope...  \n",
       "146  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "147  https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "148  https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "149  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(company_name, columns=['Company Name'])\n",
    "df['Job Title'] = pd.DataFrame(job_title)\n",
    "df['Location'] = pd.DataFrame(company_location)\n",
    "df['Website URL'] = pd.DataFrame(job_url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_title_filter(x, user_input_job_title):\n",
    "    \n",
    "    s = [i.lower() for i in user_input_job_title]\n",
    "    suggestion = []\n",
    "    for i in s:\n",
    "        suggestion.extend(i.split())\n",
    "\n",
    "    s = x.split()\n",
    "    a = [i.lower() for i in s]\n",
    "    \n",
    "    intersection = list(set(suggestion).intersection(set(a)))\n",
    "    return x if len(intersection)>1 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Locuz</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zupee</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluentgrid Limited</td>\n",
       "      <td>Fluentgrid Limited - Data Scientist - Artifici...</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/fluentgrid-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Sr Software Engineer - Data Analytics</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-software-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQuest Solutions Corporation</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Vaishnavi Services</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Nafra, Arunachal Pradesh, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Walmart Global Tech India</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Chennai, Tamil Nadu, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Tech Mahindra (formerly Mahindra Satyam)</td>\n",
       "      <td>GCP Developer / GCP Cloud Data engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/gcp-develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Think Future Technologies</td>\n",
       "      <td>Data Engineer (GCP)</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Careator Technologies</td>\n",
       "      <td>Data Engineer - SQL/Python</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Company Name  \\\n",
       "0                                      Locuz   \n",
       "1                                      Zupee   \n",
       "2                         Fluentgrid Limited   \n",
       "3                                   OneTrust   \n",
       "4               IQuest Solutions Corporation   \n",
       "..                                       ...   \n",
       "75                        Vaishnavi Services   \n",
       "76                 Walmart Global Tech India   \n",
       "77  Tech Mahindra (formerly Mahindra Satyam)   \n",
       "78                 Think Future Technologies   \n",
       "79                     Careator Technologies   \n",
       "\n",
       "                                            Job Title  \\\n",
       "0                           Machine Learning Engineer   \n",
       "1                                       Data Engineer   \n",
       "2   Fluentgrid Limited - Data Scientist - Artifici...   \n",
       "3               Sr Software Engineer - Data Analytics   \n",
       "4                                       Data Engineer   \n",
       "..                                                ...   \n",
       "75                          Machine Learning Engineer   \n",
       "76                               Senior Data Engineer   \n",
       "77            GCP Developer / GCP Cloud Data engineer   \n",
       "78                                Data Engineer (GCP)   \n",
       "79                         Data Engineer - SQL/Python   \n",
       "\n",
       "                           Location  \\\n",
       "0       Hyderabad, Telangana, India   \n",
       "1          Gurugram, Haryana, India   \n",
       "2       Hyderabad, Telangana, India   \n",
       "3       Bengaluru, Karnataka, India   \n",
       "4       Bengaluru, Karnataka, India   \n",
       "..                              ...   \n",
       "75  Nafra, Arunachal Pradesh, India   \n",
       "76       Chennai, Tamil Nadu, India   \n",
       "77      Hyderabad, Telangana, India   \n",
       "78         Gurugram, Haryana, India   \n",
       "79      Hyderabad, Telangana, India   \n",
       "\n",
       "                                          Website URL  \n",
       "0   https://in.linkedin.com/jobs/view/machine-lear...  \n",
       "1   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "2   https://in.linkedin.com/jobs/view/fluentgrid-l...  \n",
       "3   https://in.linkedin.com/jobs/view/sr-software-...  \n",
       "4   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "..                                                ...  \n",
       "75  https://in.linkedin.com/jobs/view/machine-lear...  \n",
       "76  https://in.linkedin.com/jobs/view/senior-data-...  \n",
       "77  https://in.linkedin.com/jobs/view/gcp-develope...  \n",
       "78  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "79  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Job Title'] = df['Job Title'].apply(lambda x: job_title_filter(x, user_input_job_title))\n",
    "df=df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Locuz</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zupee</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluentgrid Limited</td>\n",
       "      <td>Fluentgrid Limited - Data Scientist - Artifici...</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/fluentgrid-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Sr Software Engineer - Data Analytics</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-software-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQuest Solutions Corporation</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TIGI HR ®</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nice Software Solutions Pvt. Ltd.</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ripik.AI</td>\n",
       "      <td>Ripik.ai - Data Scientist - Artificial Intelli...</td>\n",
       "      <td>Jharkhand, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/ripik-ai-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Awign</td>\n",
       "      <td>Data Engineer - SQL/Python</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meeden Labs</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jupitice Justice Technologies</td>\n",
       "      <td>Data Scientist - Machine Learning Frameworks</td>\n",
       "      <td>Chandigarh, Chandigarh, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Response Informatics</td>\n",
       "      <td>Data Scientist - Artificial Intelligence/Machi...</td>\n",
       "      <td>Kolkata, West Bengal, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quantium</td>\n",
       "      <td>IND (New) Data Engineer - wiq</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/ind-new-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>Sr Data Science Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-data-scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sanofi</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/lead-data-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Berkadia</td>\n",
       "      <td>Manager, Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/manager-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEC Software Solutions</td>\n",
       "      <td>Data Engineer / Senior Data Engineer - GCP, Bi...</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Esri</td>\n",
       "      <td>Product Engineer II - Geospatial Data Science</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/product-engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Staff Data Engineer, Crypto Core</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/staff-data-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Looper Development Services</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Senior Data Engineer, Crypto Core</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GlobalFoundries</td>\n",
       "      <td>Data Engineer - Machine Learning/Data Science</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Berkadia</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Greenlight</td>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AXA XL</td>\n",
       "      <td>Assistant Scientist, Business Data Services</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/assistant-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEKGENCE INC</td>\n",
       "      <td>Python Data Testing engineer - 5 to 7 years- B...</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/python-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>V Support Solutions</td>\n",
       "      <td>ETL and data engineer 5 - 6 Years</td>\n",
       "      <td>Coimbatore, Tamil Nadu, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/etl-and-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Quarks</td>\n",
       "      <td>Data Engineer - ETL/Data Pipeline</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Avalara</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NEC Software Solutions (India)</td>\n",
       "      <td>Data Engineer / Senior Data Engineer - GCP, Bi...</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company Name  \\\n",
       "0                               Locuz   \n",
       "1                               Zupee   \n",
       "2                  Fluentgrid Limited   \n",
       "3                            OneTrust   \n",
       "4        IQuest Solutions Corporation   \n",
       "5                           TIGI HR ®   \n",
       "6   Nice Software Solutions Pvt. Ltd.   \n",
       "7                            Ripik.AI   \n",
       "8                               Awign   \n",
       "9                         Meeden Labs   \n",
       "10      Jupitice Justice Technologies   \n",
       "11               Response Informatics   \n",
       "12                           Quantium   \n",
       "13                              Adobe   \n",
       "14                             Sanofi   \n",
       "15                           Berkadia   \n",
       "16             NEC Software Solutions   \n",
       "17                               Esri   \n",
       "18                             Gemini   \n",
       "19        Looper Development Services   \n",
       "20                             Gemini   \n",
       "21                    GlobalFoundries   \n",
       "22                           Berkadia   \n",
       "23                         Greenlight   \n",
       "24                             AXA XL   \n",
       "25                       TEKGENCE INC   \n",
       "26                V Support Solutions   \n",
       "27                             Quarks   \n",
       "28                            Avalara   \n",
       "29     NEC Software Solutions (India)   \n",
       "\n",
       "                                            Job Title  \\\n",
       "0                           Machine Learning Engineer   \n",
       "1                                       Data Engineer   \n",
       "2   Fluentgrid Limited - Data Scientist - Artifici...   \n",
       "3               Sr Software Engineer - Data Analytics   \n",
       "4                                       Data Engineer   \n",
       "5                                Senior Data Engineer   \n",
       "6                                       Data Engineer   \n",
       "7   Ripik.ai - Data Scientist - Artificial Intelli...   \n",
       "8                          Data Engineer - SQL/Python   \n",
       "9                                       Data Engineer   \n",
       "10       Data Scientist - Machine Learning Frameworks   \n",
       "11  Data Scientist - Artificial Intelligence/Machi...   \n",
       "12                      IND (New) Data Engineer - wiq   \n",
       "13                           Sr Data Science Engineer   \n",
       "14                                 Lead Data Engineer   \n",
       "15                             Manager, Data Engineer   \n",
       "16  Data Engineer / Senior Data Engineer - GCP, Bi...   \n",
       "17      Product Engineer II - Geospatial Data Science   \n",
       "18                   Staff Data Engineer, Crypto Core   \n",
       "19                                      Data Engineer   \n",
       "20                  Senior Data Engineer, Crypto Core   \n",
       "21      Data Engineer - Machine Learning/Data Science   \n",
       "22                               Senior Data Engineer   \n",
       "23                            Data Analytics Engineer   \n",
       "24        Assistant Scientist, Business Data Services   \n",
       "25  Python Data Testing engineer - 5 to 7 years- B...   \n",
       "26                  ETL and data engineer 5 - 6 Years   \n",
       "27                  Data Engineer - ETL/Data Pipeline   \n",
       "28                                      Data Engineer   \n",
       "29  Data Engineer / Senior Data Engineer - GCP, Bi...   \n",
       "\n",
       "                             Location  \\\n",
       "0         Hyderabad, Telangana, India   \n",
       "1            Gurugram, Haryana, India   \n",
       "2         Hyderabad, Telangana, India   \n",
       "3         Bengaluru, Karnataka, India   \n",
       "4         Bengaluru, Karnataka, India   \n",
       "5                               India   \n",
       "6            Pune, Maharashtra, India   \n",
       "7                    Jharkhand, India   \n",
       "8         Bengaluru, Karnataka, India   \n",
       "9         Bengaluru, Karnataka, India   \n",
       "10      Chandigarh, Chandigarh, India   \n",
       "11        Kolkata, West Bengal, India   \n",
       "12        Hyderabad, Telangana, India   \n",
       "13        Bengaluru, Karnataka, India   \n",
       "14        Hyderabad, Telangana, India   \n",
       "15        Bengaluru, Karnataka, India   \n",
       "16         Mumbai, Maharashtra, India   \n",
       "17            New Delhi, Delhi, India   \n",
       "18            Gurgaon, Haryana, India   \n",
       "19         Mumbai, Maharashtra, India   \n",
       "20            Gurgaon, Haryana, India   \n",
       "21  Bangalore Urban, Karnataka, India   \n",
       "22        Hyderabad, Telangana, India   \n",
       "23        Bengaluru, Karnataka, India   \n",
       "24            Gurgaon, Haryana, India   \n",
       "25        Bengaluru, Karnataka, India   \n",
       "26      Coimbatore, Tamil Nadu, India   \n",
       "27           Gurugram, Haryana, India   \n",
       "28           Pune, Maharashtra, India   \n",
       "29         Mumbai, Maharashtra, India   \n",
       "\n",
       "                                          Website URL  \n",
       "0   https://in.linkedin.com/jobs/view/machine-lear...  \n",
       "1   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "2   https://in.linkedin.com/jobs/view/fluentgrid-l...  \n",
       "3   https://in.linkedin.com/jobs/view/sr-software-...  \n",
       "4   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "5   https://in.linkedin.com/jobs/view/senior-data-...  \n",
       "6   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "7   https://in.linkedin.com/jobs/view/ripik-ai-dat...  \n",
       "8   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "9   https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "10  https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "11  https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "12  https://in.linkedin.com/jobs/view/ind-new-data...  \n",
       "13  https://in.linkedin.com/jobs/view/sr-data-scie...  \n",
       "14  https://in.linkedin.com/jobs/view/lead-data-en...  \n",
       "15  https://in.linkedin.com/jobs/view/manager-data...  \n",
       "16  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "17  https://in.linkedin.com/jobs/view/product-engi...  \n",
       "18  https://in.linkedin.com/jobs/view/staff-data-e...  \n",
       "19  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "20  https://in.linkedin.com/jobs/view/senior-data-...  \n",
       "21  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "22  https://in.linkedin.com/jobs/view/senior-data-...  \n",
       "23  https://in.linkedin.com/jobs/view/data-analyti...  \n",
       "24  https://in.linkedin.com/jobs/view/assistant-sc...  \n",
       "25  https://in.linkedin.com/jobs/view/python-data-...  \n",
       "26  https://in.linkedin.com/jobs/view/etl-and-data...  \n",
       "27  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "28  https://in.linkedin.com/jobs/view/data-enginee...  \n",
       "29  https://in.linkedin.com/jobs/view/data-enginee...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.iloc[:30,:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(link):\n",
    "    driver.get(link)\n",
    "    driver.find_element(by=By.CLASS_NAME, value='show-more-less-html__button').click()\n",
    "    description = driver.find_elements(by=By.CLASS_NAME, value='show-more-less-html')\n",
    "    driver.implicitly_wait(4)\n",
    "    \n",
    "    for j in description:\n",
    "            text = j.text.replace('Show less','')\n",
    "            return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = df['Website URL'].tolist()\n",
    "\n",
    "job_description = []\n",
    "\n",
    "for i in range(0, len(website_url)):\n",
    "    link = website_url[i]\n",
    "    time.sleep(5)\n",
    "    data = description(link)\n",
    "    if data is not None and len(data.strip()) > 0:\n",
    "        job_description.append(data)\n",
    "    else:\n",
    "        job_description.append('Description Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Locuz</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n",
       "      <td>Now!\\nWE ARE HIRING “Machine Learning Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zupee</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>About Us\\n\\nZupee is India’s fastest growing T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluentgrid Limited</td>\n",
       "      <td>Fluentgrid Limited - Data Scientist - Artifici...</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/fluentgrid-l...</td>\n",
       "      <td>Job Description\\n\\nWe are looking for Data Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Sr Software Engineer - Data Analytics</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-software-...</td>\n",
       "      <td>Strength in Trust\\n\\nAt OneTrust, we help busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQuest Solutions Corporation</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Title / Advertise Job Title: Sr. Specialis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TIGI HR ®</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>Greetings from TiGi HR…!\\n\\nWe are hiring for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nice Software Solutions Pvt. Ltd.</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>NICE SOFTWARE SOLUTIONS\\n\\nNice Software Solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ripik.AI</td>\n",
       "      <td>Ripik.ai - Data Scientist - Artificial Intelli...</td>\n",
       "      <td>Jharkhand, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/ripik-ai-dat...</td>\n",
       "      <td>Job Description For Data Scientist\\n\\nAbout us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Awign</td>\n",
       "      <td>Data Engineer - SQL/Python</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Description\\n\\nRoles &amp; Responsibilities :\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meeden Labs</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Hi All ,\\n\\nWe are #hiring for Data Engineer (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jupitice Justice Technologies</td>\n",
       "      <td>Data Scientist - Machine Learning Frameworks</td>\n",
       "      <td>Chandigarh, Chandigarh, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Data Scientist\\n\\nRequirements :\\n\\nStrong und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Response Informatics</td>\n",
       "      <td>Data Scientist - Artificial Intelligence/Machi...</td>\n",
       "      <td>Kolkata, West Bengal, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Job Description\\n\\nExperience in statistical m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quantium</td>\n",
       "      <td>IND (New) Data Engineer - wiq</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/ind-new-data...</td>\n",
       "      <td>Role Summary\\n\\nAs an Engineer you will be res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>Sr Data Science Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-data-scie...</td>\n",
       "      <td>Our Company\\n\\nChanging the world through digi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sanofi</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/lead-data-en...</td>\n",
       "      <td>About Sanofi:\\n\\nWe are an innovative global h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Berkadia</td>\n",
       "      <td>Manager, Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/manager-data...</td>\n",
       "      <td>Job Title: Manager, Data Engineering\\n\\nLine o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEC Software Solutions</td>\n",
       "      <td>Data Engineer / Senior Data Engineer - GCP, Bi...</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Company Description\\n\\nNEC Software Solutions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Esri</td>\n",
       "      <td>Product Engineer II - Geospatial Data Science</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/product-engi...</td>\n",
       "      <td>Overview\\n\\nAre you passionate about applying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Staff Data Engineer, Crypto Core</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/staff-data-e...</td>\n",
       "      <td>About The Company\\n\\nGemini is a global crypto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Looper Development Services</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Description:\\nPosition Overview:\\nAs a Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Senior Data Engineer, Crypto Core</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>About The Company\\n\\nGemini is a global crypto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GlobalFoundries</td>\n",
       "      <td>Data Engineer - Machine Learning/Data Science</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>About GLOBALFOUNDRIES\\n\\nGlobalFoundries is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Berkadia</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>To Be Completed By Manager\\n\\nShift: 3:00pm to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Greenlight</td>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-analyti...</td>\n",
       "      <td>Greenlight is the leading family fintech compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AXA XL</td>\n",
       "      <td>Assistant Scientist, Business Data Services</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/assistant-sc...</td>\n",
       "      <td>AXA XL offers risk transfer and risk managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEKGENCE INC</td>\n",
       "      <td>Python Data Testing engineer - 5 to 7 years- B...</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/python-data-...</td>\n",
       "      <td>Job Title : Python Data Testing engineer\\nLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>V Support Solutions</td>\n",
       "      <td>ETL and data engineer 5 - 6 Years</td>\n",
       "      <td>Coimbatore, Tamil Nadu, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/etl-and-data...</td>\n",
       "      <td>Job Description:\\nBachelor's degree in Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Quarks</td>\n",
       "      <td>Data Engineer - ETL/Data Pipeline</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Responsibilities (Must Haves)\\n\\nDesign, build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Avalara</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Summary:\\nThis Senior Software Enginner in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NEC Software Solutions (India)</td>\n",
       "      <td>Data Engineer / Senior Data Engineer - GCP, Bi...</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Company Description\\n\\nNEC Software Solutions ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company Name  \\\n",
       "0                               Locuz   \n",
       "1                               Zupee   \n",
       "2                  Fluentgrid Limited   \n",
       "3                            OneTrust   \n",
       "4        IQuest Solutions Corporation   \n",
       "5                           TIGI HR ®   \n",
       "6   Nice Software Solutions Pvt. Ltd.   \n",
       "7                            Ripik.AI   \n",
       "8                               Awign   \n",
       "9                         Meeden Labs   \n",
       "10      Jupitice Justice Technologies   \n",
       "11               Response Informatics   \n",
       "12                           Quantium   \n",
       "13                              Adobe   \n",
       "14                             Sanofi   \n",
       "15                           Berkadia   \n",
       "16             NEC Software Solutions   \n",
       "17                               Esri   \n",
       "18                             Gemini   \n",
       "19        Looper Development Services   \n",
       "20                             Gemini   \n",
       "21                    GlobalFoundries   \n",
       "22                           Berkadia   \n",
       "23                         Greenlight   \n",
       "24                             AXA XL   \n",
       "25                       TEKGENCE INC   \n",
       "26                V Support Solutions   \n",
       "27                             Quarks   \n",
       "28                            Avalara   \n",
       "29     NEC Software Solutions (India)   \n",
       "\n",
       "                                            Job Title  \\\n",
       "0                           Machine Learning Engineer   \n",
       "1                                       Data Engineer   \n",
       "2   Fluentgrid Limited - Data Scientist - Artifici...   \n",
       "3               Sr Software Engineer - Data Analytics   \n",
       "4                                       Data Engineer   \n",
       "5                                Senior Data Engineer   \n",
       "6                                       Data Engineer   \n",
       "7   Ripik.ai - Data Scientist - Artificial Intelli...   \n",
       "8                          Data Engineer - SQL/Python   \n",
       "9                                       Data Engineer   \n",
       "10       Data Scientist - Machine Learning Frameworks   \n",
       "11  Data Scientist - Artificial Intelligence/Machi...   \n",
       "12                      IND (New) Data Engineer - wiq   \n",
       "13                           Sr Data Science Engineer   \n",
       "14                                 Lead Data Engineer   \n",
       "15                             Manager, Data Engineer   \n",
       "16  Data Engineer / Senior Data Engineer - GCP, Bi...   \n",
       "17      Product Engineer II - Geospatial Data Science   \n",
       "18                   Staff Data Engineer, Crypto Core   \n",
       "19                                      Data Engineer   \n",
       "20                  Senior Data Engineer, Crypto Core   \n",
       "21      Data Engineer - Machine Learning/Data Science   \n",
       "22                               Senior Data Engineer   \n",
       "23                            Data Analytics Engineer   \n",
       "24        Assistant Scientist, Business Data Services   \n",
       "25  Python Data Testing engineer - 5 to 7 years- B...   \n",
       "26                  ETL and data engineer 5 - 6 Years   \n",
       "27                  Data Engineer - ETL/Data Pipeline   \n",
       "28                                      Data Engineer   \n",
       "29  Data Engineer / Senior Data Engineer - GCP, Bi...   \n",
       "\n",
       "                             Location  \\\n",
       "0         Hyderabad, Telangana, India   \n",
       "1            Gurugram, Haryana, India   \n",
       "2         Hyderabad, Telangana, India   \n",
       "3         Bengaluru, Karnataka, India   \n",
       "4         Bengaluru, Karnataka, India   \n",
       "5                               India   \n",
       "6            Pune, Maharashtra, India   \n",
       "7                    Jharkhand, India   \n",
       "8         Bengaluru, Karnataka, India   \n",
       "9         Bengaluru, Karnataka, India   \n",
       "10      Chandigarh, Chandigarh, India   \n",
       "11        Kolkata, West Bengal, India   \n",
       "12        Hyderabad, Telangana, India   \n",
       "13        Bengaluru, Karnataka, India   \n",
       "14        Hyderabad, Telangana, India   \n",
       "15        Bengaluru, Karnataka, India   \n",
       "16         Mumbai, Maharashtra, India   \n",
       "17            New Delhi, Delhi, India   \n",
       "18            Gurgaon, Haryana, India   \n",
       "19         Mumbai, Maharashtra, India   \n",
       "20            Gurgaon, Haryana, India   \n",
       "21  Bangalore Urban, Karnataka, India   \n",
       "22        Hyderabad, Telangana, India   \n",
       "23        Bengaluru, Karnataka, India   \n",
       "24            Gurgaon, Haryana, India   \n",
       "25        Bengaluru, Karnataka, India   \n",
       "26      Coimbatore, Tamil Nadu, India   \n",
       "27           Gurugram, Haryana, India   \n",
       "28           Pune, Maharashtra, India   \n",
       "29         Mumbai, Maharashtra, India   \n",
       "\n",
       "                                          Website URL  \\\n",
       "0   https://in.linkedin.com/jobs/view/machine-lear...   \n",
       "1   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "2   https://in.linkedin.com/jobs/view/fluentgrid-l...   \n",
       "3   https://in.linkedin.com/jobs/view/sr-software-...   \n",
       "4   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "5   https://in.linkedin.com/jobs/view/senior-data-...   \n",
       "6   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "7   https://in.linkedin.com/jobs/view/ripik-ai-dat...   \n",
       "8   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "9   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "10  https://in.linkedin.com/jobs/view/data-scienti...   \n",
       "11  https://in.linkedin.com/jobs/view/data-scienti...   \n",
       "12  https://in.linkedin.com/jobs/view/ind-new-data...   \n",
       "13  https://in.linkedin.com/jobs/view/sr-data-scie...   \n",
       "14  https://in.linkedin.com/jobs/view/lead-data-en...   \n",
       "15  https://in.linkedin.com/jobs/view/manager-data...   \n",
       "16  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "17  https://in.linkedin.com/jobs/view/product-engi...   \n",
       "18  https://in.linkedin.com/jobs/view/staff-data-e...   \n",
       "19  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "20  https://in.linkedin.com/jobs/view/senior-data-...   \n",
       "21  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "22  https://in.linkedin.com/jobs/view/senior-data-...   \n",
       "23  https://in.linkedin.com/jobs/view/data-analyti...   \n",
       "24  https://in.linkedin.com/jobs/view/assistant-sc...   \n",
       "25  https://in.linkedin.com/jobs/view/python-data-...   \n",
       "26  https://in.linkedin.com/jobs/view/etl-and-data...   \n",
       "27  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "28  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "29  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "\n",
       "                                      Job Description  \n",
       "0   Now!\\nWE ARE HIRING “Machine Learning Engineer...  \n",
       "1   About Us\\n\\nZupee is India’s fastest growing T...  \n",
       "2   Job Description\\n\\nWe are looking for Data Sci...  \n",
       "3   Strength in Trust\\n\\nAt OneTrust, we help busi...  \n",
       "4   Job Title / Advertise Job Title: Sr. Specialis...  \n",
       "5   Greetings from TiGi HR…!\\n\\nWe are hiring for ...  \n",
       "6   NICE SOFTWARE SOLUTIONS\\n\\nNice Software Solut...  \n",
       "7   Job Description For Data Scientist\\n\\nAbout us...  \n",
       "8   Job Description\\n\\nRoles & Responsibilities :\\...  \n",
       "9   Hi All ,\\n\\nWe are #hiring for Data Engineer (...  \n",
       "10  Data Scientist\\n\\nRequirements :\\n\\nStrong und...  \n",
       "11  Job Description\\n\\nExperience in statistical m...  \n",
       "12  Role Summary\\n\\nAs an Engineer you will be res...  \n",
       "13  Our Company\\n\\nChanging the world through digi...  \n",
       "14  About Sanofi:\\n\\nWe are an innovative global h...  \n",
       "15  Job Title: Manager, Data Engineering\\n\\nLine o...  \n",
       "16  Company Description\\n\\nNEC Software Solutions ...  \n",
       "17  Overview\\n\\nAre you passionate about applying ...  \n",
       "18  About The Company\\n\\nGemini is a global crypto...  \n",
       "19  Job Description:\\nPosition Overview:\\nAs a Dat...  \n",
       "20  About The Company\\n\\nGemini is a global crypto...  \n",
       "21  About GLOBALFOUNDRIES\\n\\nGlobalFoundries is a ...  \n",
       "22  To Be Completed By Manager\\n\\nShift: 3:00pm to...  \n",
       "23  Greenlight is the leading family fintech compa...  \n",
       "24  AXA XL offers risk transfer and risk managemen...  \n",
       "25  Job Title : Python Data Testing engineer\\nLoca...  \n",
       "26  Job Description:\\nBachelor's degree in Compute...  \n",
       "27  Responsibilities (Must Haves)\\n\\nDesign, build...  \n",
       "28  Job Summary:\\nThis Senior Software Enginner in...  \n",
       "29  Company Description\\n\\nNEC Software Solutions ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Job Description'] = pd.DataFrame(job_description, columns=['Description'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('linkedin_scarp_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Locuz</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/machine-lear...</td>\n",
       "      <td>Now!\\nWE ARE HIRING “Machine Learning Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zupee</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>About Us\\n\\nZupee is India’s fastest growing T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluentgrid Limited</td>\n",
       "      <td>Fluentgrid Limited - Data Scientist - Artifici...</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/fluentgrid-l...</td>\n",
       "      <td>Job Description\\n\\nWe are looking for Data Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Sr Software Engineer - Data Analytics</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-software-...</td>\n",
       "      <td>Strength in Trust\\n\\nAt OneTrust, we help busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQuest Solutions Corporation</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Title / Advertise Job Title: Sr. Specialis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TIGI HR ®</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>Greetings from TiGi HR…!\\n\\nWe are hiring for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nice Software Solutions Pvt. Ltd.</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>NICE SOFTWARE SOLUTIONS\\n\\nNice Software Solut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ripik.AI</td>\n",
       "      <td>Ripik.ai - Data Scientist - Artificial Intelli...</td>\n",
       "      <td>Jharkhand, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/ripik-ai-dat...</td>\n",
       "      <td>Job Description For Data Scientist\\n\\nAbout us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Awign</td>\n",
       "      <td>Data Engineer - SQL/Python</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Description\\n\\nRoles &amp; Responsibilities :\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meeden Labs</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Hi All ,\\n\\nWe are #hiring for Data Engineer (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jupitice Justice Technologies</td>\n",
       "      <td>Data Scientist - Machine Learning Frameworks</td>\n",
       "      <td>Chandigarh, Chandigarh, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Data Scientist\\n\\nRequirements :\\n\\nStrong und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Response Informatics</td>\n",
       "      <td>Data Scientist - Artificial Intelligence/Machi...</td>\n",
       "      <td>Kolkata, West Bengal, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "      <td>Job Description\\n\\nExperience in statistical m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quantium</td>\n",
       "      <td>IND (New) Data Engineer - wiq</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/ind-new-data...</td>\n",
       "      <td>Role Summary\\n\\nAs an Engineer you will be res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>Sr Data Science Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/sr-data-scie...</td>\n",
       "      <td>Our Company\\n\\nChanging the world through digi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sanofi</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/lead-data-en...</td>\n",
       "      <td>About Sanofi:\\n\\nWe are an innovative global h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Berkadia</td>\n",
       "      <td>Manager, Data Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/manager-data...</td>\n",
       "      <td>Job Title: Manager, Data Engineering\\n\\nLine o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEC Software Solutions</td>\n",
       "      <td>Data Engineer / Senior Data Engineer - GCP, Bi...</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Company Description\\n\\nNEC Software Solutions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Esri</td>\n",
       "      <td>Product Engineer II - Geospatial Data Science</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/product-engi...</td>\n",
       "      <td>Overview\\n\\nAre you passionate about applying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Staff Data Engineer, Crypto Core</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/staff-data-e...</td>\n",
       "      <td>About The Company\\n\\nGemini is a global crypto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Looper Development Services</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Description:\\nPosition Overview:\\nAs a Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>Senior Data Engineer, Crypto Core</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>About The Company\\n\\nGemini is a global crypto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GlobalFoundries</td>\n",
       "      <td>Data Engineer - Machine Learning/Data Science</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>About GLOBALFOUNDRIES\\n\\nGlobalFoundries is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Berkadia</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/senior-data-...</td>\n",
       "      <td>To Be Completed By Manager\\n\\nShift: 3:00pm to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Greenlight</td>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-analyti...</td>\n",
       "      <td>Greenlight is the leading family fintech compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AXA XL</td>\n",
       "      <td>Assistant Scientist, Business Data Services</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/assistant-sc...</td>\n",
       "      <td>AXA XL offers risk transfer and risk managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEKGENCE INC</td>\n",
       "      <td>Python Data Testing engineer - 5 to 7 years- B...</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/python-data-...</td>\n",
       "      <td>Job Title : Python Data Testing engineer\\nLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>V Support Solutions</td>\n",
       "      <td>ETL and data engineer 5 - 6 Years</td>\n",
       "      <td>Coimbatore, Tamil Nadu, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/etl-and-data...</td>\n",
       "      <td>Job Description:\\nBachelor's degree in Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Quarks</td>\n",
       "      <td>Data Engineer - ETL/Data Pipeline</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Responsibilities (Must Haves)\\n\\nDesign, build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Avalara</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Job Summary:\\nThis Senior Software Enginner in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NEC Software Solutions (India)</td>\n",
       "      <td>Data Engineer / Senior Data Engineer - GCP, Bi...</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>Company Description\\n\\nNEC Software Solutions ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company Name  \\\n",
       "0                               Locuz   \n",
       "1                               Zupee   \n",
       "2                  Fluentgrid Limited   \n",
       "3                            OneTrust   \n",
       "4        IQuest Solutions Corporation   \n",
       "5                           TIGI HR ®   \n",
       "6   Nice Software Solutions Pvt. Ltd.   \n",
       "7                            Ripik.AI   \n",
       "8                               Awign   \n",
       "9                         Meeden Labs   \n",
       "10      Jupitice Justice Technologies   \n",
       "11               Response Informatics   \n",
       "12                           Quantium   \n",
       "13                              Adobe   \n",
       "14                             Sanofi   \n",
       "15                           Berkadia   \n",
       "16             NEC Software Solutions   \n",
       "17                               Esri   \n",
       "18                             Gemini   \n",
       "19        Looper Development Services   \n",
       "20                             Gemini   \n",
       "21                    GlobalFoundries   \n",
       "22                           Berkadia   \n",
       "23                         Greenlight   \n",
       "24                             AXA XL   \n",
       "25                       TEKGENCE INC   \n",
       "26                V Support Solutions   \n",
       "27                             Quarks   \n",
       "28                            Avalara   \n",
       "29     NEC Software Solutions (India)   \n",
       "\n",
       "                                            Job Title  \\\n",
       "0                           Machine Learning Engineer   \n",
       "1                                       Data Engineer   \n",
       "2   Fluentgrid Limited - Data Scientist - Artifici...   \n",
       "3               Sr Software Engineer - Data Analytics   \n",
       "4                                       Data Engineer   \n",
       "5                                Senior Data Engineer   \n",
       "6                                       Data Engineer   \n",
       "7   Ripik.ai - Data Scientist - Artificial Intelli...   \n",
       "8                          Data Engineer - SQL/Python   \n",
       "9                                       Data Engineer   \n",
       "10       Data Scientist - Machine Learning Frameworks   \n",
       "11  Data Scientist - Artificial Intelligence/Machi...   \n",
       "12                      IND (New) Data Engineer - wiq   \n",
       "13                           Sr Data Science Engineer   \n",
       "14                                 Lead Data Engineer   \n",
       "15                             Manager, Data Engineer   \n",
       "16  Data Engineer / Senior Data Engineer - GCP, Bi...   \n",
       "17      Product Engineer II - Geospatial Data Science   \n",
       "18                   Staff Data Engineer, Crypto Core   \n",
       "19                                      Data Engineer   \n",
       "20                  Senior Data Engineer, Crypto Core   \n",
       "21      Data Engineer - Machine Learning/Data Science   \n",
       "22                               Senior Data Engineer   \n",
       "23                            Data Analytics Engineer   \n",
       "24        Assistant Scientist, Business Data Services   \n",
       "25  Python Data Testing engineer - 5 to 7 years- B...   \n",
       "26                  ETL and data engineer 5 - 6 Years   \n",
       "27                  Data Engineer - ETL/Data Pipeline   \n",
       "28                                      Data Engineer   \n",
       "29  Data Engineer / Senior Data Engineer - GCP, Bi...   \n",
       "\n",
       "                             Location  \\\n",
       "0         Hyderabad, Telangana, India   \n",
       "1            Gurugram, Haryana, India   \n",
       "2         Hyderabad, Telangana, India   \n",
       "3         Bengaluru, Karnataka, India   \n",
       "4         Bengaluru, Karnataka, India   \n",
       "5                               India   \n",
       "6            Pune, Maharashtra, India   \n",
       "7                    Jharkhand, India   \n",
       "8         Bengaluru, Karnataka, India   \n",
       "9         Bengaluru, Karnataka, India   \n",
       "10      Chandigarh, Chandigarh, India   \n",
       "11        Kolkata, West Bengal, India   \n",
       "12        Hyderabad, Telangana, India   \n",
       "13        Bengaluru, Karnataka, India   \n",
       "14        Hyderabad, Telangana, India   \n",
       "15        Bengaluru, Karnataka, India   \n",
       "16         Mumbai, Maharashtra, India   \n",
       "17            New Delhi, Delhi, India   \n",
       "18            Gurgaon, Haryana, India   \n",
       "19         Mumbai, Maharashtra, India   \n",
       "20            Gurgaon, Haryana, India   \n",
       "21  Bangalore Urban, Karnataka, India   \n",
       "22        Hyderabad, Telangana, India   \n",
       "23        Bengaluru, Karnataka, India   \n",
       "24            Gurgaon, Haryana, India   \n",
       "25        Bengaluru, Karnataka, India   \n",
       "26      Coimbatore, Tamil Nadu, India   \n",
       "27           Gurugram, Haryana, India   \n",
       "28           Pune, Maharashtra, India   \n",
       "29         Mumbai, Maharashtra, India   \n",
       "\n",
       "                                          Website URL  \\\n",
       "0   https://in.linkedin.com/jobs/view/machine-lear...   \n",
       "1   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "2   https://in.linkedin.com/jobs/view/fluentgrid-l...   \n",
       "3   https://in.linkedin.com/jobs/view/sr-software-...   \n",
       "4   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "5   https://in.linkedin.com/jobs/view/senior-data-...   \n",
       "6   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "7   https://in.linkedin.com/jobs/view/ripik-ai-dat...   \n",
       "8   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "9   https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "10  https://in.linkedin.com/jobs/view/data-scienti...   \n",
       "11  https://in.linkedin.com/jobs/view/data-scienti...   \n",
       "12  https://in.linkedin.com/jobs/view/ind-new-data...   \n",
       "13  https://in.linkedin.com/jobs/view/sr-data-scie...   \n",
       "14  https://in.linkedin.com/jobs/view/lead-data-en...   \n",
       "15  https://in.linkedin.com/jobs/view/manager-data...   \n",
       "16  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "17  https://in.linkedin.com/jobs/view/product-engi...   \n",
       "18  https://in.linkedin.com/jobs/view/staff-data-e...   \n",
       "19  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "20  https://in.linkedin.com/jobs/view/senior-data-...   \n",
       "21  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "22  https://in.linkedin.com/jobs/view/senior-data-...   \n",
       "23  https://in.linkedin.com/jobs/view/data-analyti...   \n",
       "24  https://in.linkedin.com/jobs/view/assistant-sc...   \n",
       "25  https://in.linkedin.com/jobs/view/python-data-...   \n",
       "26  https://in.linkedin.com/jobs/view/etl-and-data...   \n",
       "27  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "28  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "29  https://in.linkedin.com/jobs/view/data-enginee...   \n",
       "\n",
       "                                      Job Description  \n",
       "0   Now!\\nWE ARE HIRING “Machine Learning Engineer...  \n",
       "1   About Us\\n\\nZupee is India’s fastest growing T...  \n",
       "2   Job Description\\n\\nWe are looking for Data Sci...  \n",
       "3   Strength in Trust\\n\\nAt OneTrust, we help busi...  \n",
       "4   Job Title / Advertise Job Title: Sr. Specialis...  \n",
       "5   Greetings from TiGi HR…!\\n\\nWe are hiring for ...  \n",
       "6   NICE SOFTWARE SOLUTIONS\\n\\nNice Software Solut...  \n",
       "7   Job Description For Data Scientist\\n\\nAbout us...  \n",
       "8   Job Description\\n\\nRoles & Responsibilities :\\...  \n",
       "9   Hi All ,\\n\\nWe are #hiring for Data Engineer (...  \n",
       "10  Data Scientist\\n\\nRequirements :\\n\\nStrong und...  \n",
       "11  Job Description\\n\\nExperience in statistical m...  \n",
       "12  Role Summary\\n\\nAs an Engineer you will be res...  \n",
       "13  Our Company\\n\\nChanging the world through digi...  \n",
       "14  About Sanofi:\\n\\nWe are an innovative global h...  \n",
       "15  Job Title: Manager, Data Engineering\\n\\nLine o...  \n",
       "16  Company Description\\n\\nNEC Software Solutions ...  \n",
       "17  Overview\\n\\nAre you passionate about applying ...  \n",
       "18  About The Company\\n\\nGemini is a global crypto...  \n",
       "19  Job Description:\\nPosition Overview:\\nAs a Dat...  \n",
       "20  About The Company\\n\\nGemini is a global crypto...  \n",
       "21  About GLOBALFOUNDRIES\\n\\nGlobalFoundries is a ...  \n",
       "22  To Be Completed By Manager\\n\\nShift: 3:00pm to...  \n",
       "23  Greenlight is the leading family fintech compa...  \n",
       "24  AXA XL offers risk transfer and risk managemen...  \n",
       "25  Job Title : Python Data Testing engineer\\nLoca...  \n",
       "26  Job Description:\\nBachelor's degree in Compute...  \n",
       "27  Responsibilities (Must Haves)\\n\\nDesign, build...  \n",
       "28  Job Summary:\\nThis Senior Software Enginner in...  \n",
       "29  Company Description\\n\\nNEC Software Solutions ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.read_csv('linkedin_scarp_data.csv')\n",
    "df = pd.DataFrame(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name : Locuz\n",
      "Job Title    : Machine Learning Engineer\n",
      "Location     : Hyderabad, Telangana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/machine-learning-engineer-at-locuz-3730084815?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=TMch8Uife%2FbnZNFfa37r7A%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Now!\n",
      "WE ARE HIRING “Machine Learning Engineer\"\n",
      "Looking for dynamic individuals to join our Data Science team.\n",
      "Years of Experience: 5+years(relevant)\n",
      "Work Location: Hyderabad\n",
      "Looking for immediate joiners.\n",
      "\n",
      "Job Description:\n",
      "ML Engineer\n",
      "\n",
      "We are looking for a ML engineer who will work on a broad range of cutting-edge data analytics and machine learning problems across a variety of industries. As an ML engineer, you will\n",
      "Engage with clients to understand their business context\n",
      "Translate business problems into analytical structures and solve using statistical/ML techniques\n",
      "Collaborate with a team of data scientists and engineers to embed AI and analytics into the business decision processes\n",
      "Desired Skills, Competencies & Experience:\n",
      "5+ years of relevant AI/ML experience\n",
      "Hands on experience on AWS Sagemaker, AWS Rekognition, Textract and Amazon Forecast\n",
      "Experience in Developing and enhancing algorithms and models to solve business problem\n",
      "Maintaining all models along with development and updating of code and process documentation\n",
      "Designing data science solution approaches to unstructured problems, conducting quantitative analyses and interpreting results\n",
      "Proficient in Structured programming language is a must - Python is mandatory.\n",
      "Strong SQL, Microsoft Excel, PowerPoint skills\n",
      "Data science approaches, machine learning algorithms and statistical methods.\n",
      "Excellent written and verbal communication skills\n",
      "\n",
      "\n",
      "Send your CV to: shilpa.kolapalli@locuz.com\n",
      "Company Name : Zupee\n",
      "Job Title    : Data Engineer\n",
      "Location     : Gurugram, Haryana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-at-zupee-3730082796?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=TaU4G0u3MqLgQC0qTO%2F4tw%3D%3D&position=8&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "Description  : About Us\n",
      "\n",
      "Zupee is India’s fastest growing Technology backed Behavioral Science company. We are innovating Skill-Based Gaming with a mission to become the most trusted and responsible entertainment company in the world. We have been constantly focussing on innovation of indigenous games to entertain the\n",
      "mass.\n",
      "Our strategy is to invest in our people & user experience to drive profitable growth and become the market leader in our space. We have been experiencing phenomenal growth since inception and running profitable at EBT level since Q3, 2020. We have closed Series B funding at $102 million, at a valuation $600 million.\n",
      "The company also announced a partnership with Reliance Jio Platforms, post which Zupee games will distribute its content across all customers using Jio phones. The partnership now gives Zupee the biggest reach of all gaming companies in India, transforming it from a fast-growing startup to a firm contender for the biggest gaming studio in India.\n",
      "\n",
      "\n",
      "Role: Data Engineering\n",
      "Reports to: Senior Manager- Data Engineering\n",
      "Location: Gurgaon\n",
      "\n",
      "We are looking for someone to develop the next generation of our Data platform collaborating across functions like product, marketing design, growth, strategy, customer experience and technology\n",
      "\n",
      "Core Responsibilities\n",
      "● Understand, implement, and automate ETL and data pipelines with up-to-dateindustry\n",
      "standards\n",
      "● Hands-on involvement in the design, development, and implementation of optimal andscalable\n",
      "AWS services\n",
      "\n",
      "What are we looking for?\n",
      "● S/he must have experience in Python\n",
      "● S/he must have experience in Big Data – Spark, Hadoop, Hive, HBase and Presto\n",
      "● S/he must have experience in Data Warehousing\n",
      "● S/he must have experience in building reliable and scalable ETL pipelines\n",
      "\n",
      "Qualifications and Skills\n",
      "● 1-3 years of professional experience in data engineering profile\n",
      "● BS or MS in Computer Science or similar Engineering stream\n",
      "● Hands-on experience in data warehousing tools\n",
      "● Knowledge of distributed systems such as Hadoop, Hive, Spark, and Kafka etc.\n",
      "● Experience with AWS services (EC2, RDS, S3, Athena, data pipeline/glue, lambda,\n",
      "DynamoDB etc.\n",
      "Company Name : Fluentgrid Limited\n",
      "Job Title    : Fluentgrid Limited - Data Scientist - Artificial Intelligence/Machine Learning\n",
      "Location     : Hyderabad, Telangana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/fluentgrid-limited-data-scientist-artificial-intelligence-machine-learning-at-fluentgrid-limited-3726501146?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=CaQFHukbQk2xcz39G8iuhw%3D%3D&position=14&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Description\n",
      "\n",
      "We are looking for Data Scientist with experience in AI/ML :\n",
      "\n",
      "Strong in statistical modelling and data mining techniques\n",
      "Experience in Regression, Time Series, classification, and Anomaly Detection Models\n",
      "Experience in training machine learning models and evaluating their performance using metrics like accuracy, precision, recall, and F1-score.\n",
      "Experience in Python, TensorFlow, PyTorch, scikit-learn, etc.\n",
      "Experience in MySQL/PostgreSQL/SQL Server/GaussDB\n",
      "Able to work with Business Stakeholders for requirement elaborations and feasibility Studies.\n",
      "Ability to provide guidance and development to a group of Analyst and Engineers\n",
      "Good to have Knowledge on Visualization tools like PowerBI, etc.\n",
      "\n",
      "(ref:hirist.com)\n",
      "Company Name : OneTrust\n",
      "Job Title    : Sr Software Engineer - Data Analytics\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/sr-software-engineer-data-analytics-at-onetrust-3674266803?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=y%2Bni2izVtWSbuMycM%2FtkdQ%3D%3D&position=17&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Strength in Trust\n",
      "\n",
      "At OneTrust, we help businesses around the world to make trust a competitive advantage. Our category-defining enterprise platform enables organizations to operationalize trust across privacy, security, data governance, GRC, third-party risk, ethics, and compliance, and ESG.\n",
      "\n",
      "The Challenge\n",
      "\n",
      "We are seeking a Senior Data Analytics Engineer who will play a crucial role in driving data-driven decision-making and uncovering valuable insights to bolster our Trust Platform. As a rapidly growing SaaS enterprise platform in privacy space, we recognize the importance of leveraging data to its fullest potential, and we are dedicated to investing in cutting-edge technology and infrastructure to support our data analytics initiatives.\n",
      "\n",
      "Your Mission\n",
      "\n",
      "You will be entrusted with the responsibility of designing, implementing, and optimizing our data analytics architecture to empower teams across the organization with actionable insights. You will collaborate closely with cross-functional teams to understand their data needs and deliver innovative solutions that drive strategic and operational excellence.\n",
      "\n",
      "As The Senior Data Analytics Engineer, You Will\n",
      "\n",
      "Design, develop, and maintain scalable and efficient data pipelines for processing, transforming, and aggregating data from various sources into Onetrust data lake.\n",
      "Employ advanced data analytics techniques to explore, analyze, and interpret complex datasets to identify key trends, patterns, and opportunities.\n",
      "Collaborate with business stakeholders on data requirements and translate them into actionable insights and reports.\n",
      "Create intuitive and interactive data visualizations and dashboards that effectively communicate insights to stakeholders and enable data-driven decision-making.\n",
      "Continuously monitor data pipelines and analytics processes to identify bottlenecks and areas for improvement, ensuring efficient and reliable data delivery.\n",
      "Implement data security best practices and ensure compliance with data privacy regulations.\n",
      "\n",
      "You Are\n",
      "\n",
      "A self-learner who is open to new technologies, processes, or techniques to improve your ability to deliver high-quality software. Someone who asks questions to clarify gaps in understanding.\n",
      "\n",
      "Your Experience Includes\n",
      "\n",
      "Bachelor's or Master’s degree in Computer Science, Engineering, or related technical or business field\n",
      "Minimum of 5+ years of hands-on experience with core Java, BI and analytics tools like PowerBI, Cognos Tableau or similar.\n",
      "Experience with AAS, Data bricks or Snowflake\n",
      "Strong analytical skills.\n",
      "Good communication skills.\n",
      "Excellent organizational and leadership skills\n",
      "Proven experience in high-level programming languages, like Java.\n",
      "Proven experience with database systems and SQL language.\n",
      "Strong knowledge of ETL processes, data integration and pipelines\n",
      "Proven experience in analytic data modeling.\n",
      "Proven experience in software development methodologies\n",
      "\n",
      "Resources\n",
      "\n",
      "Check out the following to learn more about OneTrust and its people:\n",
      "\n",
      "OneTrust Careers on YouTube\n",
      "@LifeatOneTrust on Instagram\n",
      "\n",
      "Your Data\n",
      "\n",
      "You have the right to have your personal data updated or removed. You also have the right to have a copy of the information OneTrust holds about you. Further details about these rights are available on the website in our Privacy Overview. You can change your mind at any time and have your personal data removed from our database. In order to do this you must contact us and let us know you wish to be removed. The request should be made on the Data Subject Request Form.\n",
      "Company Name : IQuest Solutions Corporation\n",
      "Job Title    : Data Engineer\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-at-iquest-solutions-corporation-3728595303?refId=1R7vlmV5cMGPyzQwCW8JcQ%3D%3D&trackingId=0Re2MpBPSZKXqpL%2FYJhKow%3D%3D&position=20&pageNum=0&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Title / Advertise Job Title: Sr. Specialist, Data Engineer\n",
      "\n",
      "Location:- Hyderabad ,Chennai, and Bangalore ( Candidate need to work from AT&T Office)\n",
      "\n",
      "Exp:-4- 6 Years’\n",
      "\n",
      "Education Qualification: Bachelor’s/ Master’s degree in Computer Science or related field Shift timing (if any):\n",
      "\n",
      "Shift falls typically between 12 PM to 2:30 AM India standard time. Occasionally may have to work long hours in situations when it is needed.\n",
      "\n",
      "Role: Sr. Specialist, Data Engineer\n",
      "\n",
      "Mandatory Skill Sets:- Please share the profiles which are having solid experience in : Databricks, ADF, Snowflake.\n",
      "\n",
      "Overall Experience: - should have 4-6 years of experience in Data Quality Assurance using Web Applications/Native Experience.\n",
      "\n",
      "Strong SQL Skills, Database knowledge, Deep analytics skills, Quality and testing processes, Data testing on browser, automation testing using tools like Selenium and skills to automate Data test cases and hands on experience in Web Analytics & BI tools like Adobe, Business Objects & Tableau.\n",
      "Has good understanding on analytics platform/applications, including data warehouse and data marts and tools used for data validation.\n",
      "Has good experience on various test tools from a data perspective and has background on automation testing to implement and execute on automation data testing.\n",
      "Investigates and resolves data issues across platforms and applications, including discrepancies of definition, format, and function.\n",
      "Works closely with Product Managers, Analytics Product Team, DBAs to develop deep understanding data sets being consumed within the omnichannel data space.\n",
      "Need to understand the functionality of the application/web flows/native experiences and corelate it to the data being captured along with the functionality.\n",
      "Responsible for constantly improving Data quality, Defect Management, giving perspective on Releases & Hot Fixes and provides insights and inputs to correctly make Go/No-Go discussions.\n",
      "Should be very detailed oriented and think through all the scenarios that can potentially impact a use case and execute on those scenarios and see how data gets passed/broken or does not align with the functionality been show to the customer.\n",
      "Should be a self-starter who thrives on making Development and delivery teams to fix issues and drive quality.\n",
      "Experience working with defect management software such as JIRA/ADO, TDP, JIRA, AgileCraft, etc. is preferred\n",
      "Company Name : TIGI HR ®\n",
      "Job Title    : Senior Data Engineer\n",
      "Location     : India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/senior-data-engineer-at-tigi-hr-%C2%AE-3726555876?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=Gg%2BqpaBqrMTeEXUKGlhAuw%3D%3D&position=4&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Greetings from TiGi HR…!\n",
      "\n",
      "We are hiring for Senior Data Engineer for our esteemed client an US based company who can join us Immediately.\n",
      "\n",
      "Position: - Senior Data Engineer\n",
      "Experience: - 10+Years\n",
      "CTC: - 2 - 2.5 Lacs Per Month\n",
      "Notice Period: - Immediate to 15 Days\n",
      "Job Location: - Remote\n",
      "Contract Position - 3 Months (To Be Extended upto 6 Months)\n",
      "\n",
      "Requirements:\n",
      "\n",
      "Bachelor's or Master's degree in Computer Science or a related field.\n",
      "10+ years of hands-on Software Development experience using Java or Scala.\n",
      "Strong experience developing Spark data processing pipelines.\n",
      "Strong hands-on experience in at least one major public cloud platform (Azure or AWS preferred).\n",
      "Experience with Python and Scala programming languages.\n",
      "Exceptional knowledge of Spark architecture, including Spark Core, Spark SQL, and Spark Streaming\n",
      "Proficiency with distributed computing systems and big data technologies, such as Hadoop and HDFS.\n",
      "Expertise in designing and developing scalable, fault-tolerant, distributed data processing systems.\n",
      "Proven hands-on experience with Databricks (certification preferred).\n",
      "Strong analytical and problem-solving skills\n",
      "Excellent communication and interpersonal skills, with the ability to work collaboratively with clients and team members.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Design, develop, implement, and maintain Spark data processing pipelines for our clients.\n",
      "Work with clients to identify opportunities to optimize their data processing pipelines and leverage Spark to achieve their goals.\n",
      "Collaborate with our team of engineers to design, develop, and maintain data solutions that meet client requirements.\n",
      "Conduct code reviews and ensure that best practices are being followed in the development and maintenance of Spark data processing pipelines.\n",
      "Participate in the full software development lifecycle including analysis, design, implementation, testing, and maintenance.\n",
      "Develop and maintain technical documentation, including system design documents, user manuals, and operational procedures.\n",
      "Keep up-to-date with emerging trends and technologies in the Spark ecosystem and make recommendations for future improvements.\n",
      "Company Name : Nice Software Solutions Pvt. Ltd.\n",
      "Job Title    : Data Engineer\n",
      "Location     : Pune, Maharashtra, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-at-nice-software-solutions-pvt-ltd-3726560306?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=3am6j1Cn4MVUeK2%2Bh9JVGg%3D%3D&position=5&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : NICE SOFTWARE SOLUTIONS\n",
      "\n",
      "Nice Software Solutions Pvt Ltd is one of the top business intelligence and analytics solutions delivery company. We are operating since 2008 and have offices in Pune and Dubai with our headquarters in Nagpur. We partner and offer services to customers globally. Our evolution and growth has been well-aligned with the changing dynamics in the world of analytics. Our focus is to provide our customers with scalable, futuristic, and end-to-end Business Intelligence and Data Warehousing solutions.\n",
      "\n",
      "One of our strong point of being end-to-end solution delivery partners is that we operate into consulting, implementation, training, and curriculum development for all the prime BI/ ETL/ IT technologies. Some of our technical fortes include MicroStrategy, Informatica, Tableau, Power BI, Qlik, ThoughtSpot, Appian, and Information technologies. We believe in constant upskilling and keeping our people ready for the future of technology and analytics. Our folks benefit from our internal learning and development strategies which include trainings and boot camps. Our mission and vision to keep our people up-to-date in technology makes us an expert in producing quicker, impactful, and self-driven applications to enhance the business growth from business intelligence to decision intelligence.\n",
      "\n",
      "The 'Nice' culture is about making new relationships while maintaining the old ones. We value our internal as well as external customers, equally. Our constant efforts include facilitation of data analytics/ management services, advisories, solutions, and proof of concepts. We strongly believe in the concept of 'Your Growth is Our Growth' at all levels and with all the stakeholders.\n",
      "\n",
      "\n",
      "Data Engineer\n",
      "Job Location : Nagpur/Pune\n",
      "Job Type: Full Time\n",
      "Experience: 5+ years\n",
      "\n",
      "Skill Set: Hadoop, Spark, HDFS, Hive, Sqoop, Python, Scala, Azure, SQL\n",
      "\n",
      "Primary Responsibilities:\n",
      "Create and maintain optimal Data pipeline\n",
      "Assemble large, complex data sets that meet functional / non-functional business requirements.\n",
      "Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "Keep our data separated and secure\n",
      "Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\n",
      "Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics.\n",
      "Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\n",
      "Work with data and analytics experts to strive for greater functionality in our data systems.\n",
      "\n",
      "Required Skills:\n",
      "Candidate with 5+ years of experience in a Data Engineer role. They should also have experience using the following software/tools:\n",
      "Experience in Azure, ADF, Databricks, Redshift, Datalake, Synapse, Snowflake\n",
      "Experience with stream-processing systems: Spark-Streaming, Strom etc.\n",
      "Experience with object-oriented/object function scripting languages: Python, Scala etc\n",
      "Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data\n",
      "Should be proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs. Experience with data science and machine learning tools and technologies is a plus\n",
      "Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.\n",
      "Experience with Azure cloud services is a plus\n",
      "Financial Services Knowledge is a plus\n",
      "Company Name : Ripik.AI\n",
      "Job Title    : Ripik.ai - Data Scientist - Artificial Intelligence\n",
      "Location     : Jharkhand, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/ripik-ai-data-scientist-artificial-intelligence-at-ripik-ai-3722415922?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=vgnlwCQ%2BQoo7CFvE%2FvJXCQ%3D%3D&position=6&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Description For Data Scientist\n",
      "\n",
      "About us :\n",
      "\n",
      "Ripik.ai is a fast growing industrial AI SAAS start-up founded by IIT D/ BITS alumni and with extensive experience in McKinsey, IBM, Google and others. It is backed by marquee VC funds like Accel, Venture Highway and 25+ illustrious angels including 14 unicorn founders.\n",
      "\n",
      "Ripik.ai builds patented full stack softwares for automation of decision making in the factory floor. Today, they are deployed at more than 15 of the largest and most prestigious enterprises in India including the market leaders in steel, aluminum, cement, pharma, paints, consumer goods and others.\n",
      "\n",
      "It is one of India's very few AI product start-ups to be a partner to GCP, Azure and AWS. We are also the AI partner of choice for CII, ICC and NASSCOM.\n",
      "\n",
      "About The Role\n",
      "\n",
      "You will work on some of the latest applications of AI to solve complex business problems, and demonstrate significant business value to multiple clients.\n",
      "\n",
      "Ability to understand a problem statement and implement analytical solutions techniques independently with independently / proactively / thought-leadership.\n",
      "Collaborate and Coordinate with different functional teams(engineering and product development) to implement models and monitor outcomes.\n",
      "Responsible for building new and innovative solutions leveraging data science and artificial intelligence skills / technologies to solve non-trivial problems.\n",
      "Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant.\n",
      "\n",
      "Required Skills & Experience\n",
      "\n",
      "Expert in 2-3 programming languages and willing to learn more (Python & SQL - must have; Java/Scala/NodeJS - some knowledge/experience); experienced in DEVOPS (GIT & CI/CD tools) and Agile product development.\n",
      "Platforms (Cloud platforms like GCP/Azure/AWS - preferred : Google Cloud Platform GCP)\n",
      "Some understanding of Advanced Analytics / Machine learning / Artificial intelligence (candidate would be expected to rapidly ramp up knowledge of AA/ML/AI in order to link AA/ML/AI models to data processing pipeline) ; candidates with some data science knowledge and deep software and SCADA, OPC server, etc.)\n",
      "\n",
      "Good To Have\n",
      "\n",
      "Snowflake, knowledge of Kubernetes, IOT platforms like Crosser.IO, c3.ai, PTC ThingWorx, etc.)\n",
      "Dashboard development using Power BI, Tableau, D3.JS etc.\n",
      "Open source contribution.\n",
      "Excellent verbal and written communication skills, especially the ability to share technical results and recommendations with both, technical and non-technical audience.\n",
      "Ability to perform high-level work both independently and collaboratively as a project member on multiple projects. B.E/B.Tech/M.Tech is mandatory.\n",
      "\n",
      "(ref:hirist.com)\n",
      "Company Name : Awign\n",
      "Job Title    : Data Engineer - SQL/Python\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-sql-python-at-awign-3725577076?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=oVZkblHk%2F9adbEaUjHH2Eg%3D%3D&position=12&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Description\n",
      "\n",
      "Roles & Responsibilities :\n",
      "\n",
      "Providing the organization- s data consumers high quality data sets by data curation, consolidation, and manipulation from a wide variety of large scale (terabyte and growing) sources.\n",
      "Building first-class data products and ETL processes that interact with terabytes of data on leading platforms such as Snowflake and BigQuery.\n",
      "Developing and improving Foundational datasets by creating efficient and scalable data models to be used across the organization.\n",
      "Working with our Data Science, Analytics, CRM, and Machine Learning teams.\n",
      "Responsible for the data pipelines- SLA and dependency management.\n",
      "Writing technical documentation for data solutions and presenting at design reviews.\n",
      "Solving data pipeline failure events and implementing anomaly detecting.\n",
      "\n",
      "Expertise & Qualification\n",
      "\n",
      "Technical Experience :\n",
      "\n",
      "Experience with technologies and tooling- s associated with relational databases (PostgreSQL or equivalent) and data warehouses (Snowflake, BigQuery, Hadoop/Hive, or equivalent).\n",
      "Experience with writing and optimizing SQL.\n",
      "Experience with data modeling and ETL/ELT design, including defining SLAs, performance measurements, tuning and monitoring.\n",
      "Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\n",
      "Experience with programming languages such as Python, Java and/or Scala\n",
      "Knowledge of cloud data warehouse concepts\n",
      "\n",
      "Soft Skills\n",
      "\n",
      "Excellent verbal and written communication skills\n",
      "Strong interpersonal skills and the ability to work in a fast-paced and dynamic environment.\n",
      "Ability to make progress on projects independently and enthusiasm for solving difficult problems.\n",
      "\n",
      "Required Skills\n",
      "\n",
      "Advanced SQL\n",
      "Snowflake/BigQuery/Hadoop/Hive or similar tools\n",
      "Data modeling and ETL/ELT design\n",
      "Programming experience in any language i.e. Python, Java, Scala, etc. is good to have.\n",
      "\n",
      "(ref:hirist.com)\n",
      "Company Name : Meeden Labs\n",
      "Job Title    : Data Engineer\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-at-meeden-labs-3726560802?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=zc%2FC53kZBqURrVezmJoqQA%3D%3D&position=14&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Hi All ,\n",
      "\n",
      "We are #hiring for Data Engineer (GCP - Google Cloud Platforms - minimum 1 year experience)\n",
      "\n",
      "Job Summary\n",
      "We are seeking a skilled and motivated Data Engineer with expertise in Google Cloud Platform (GCP) to join our data team. As a Data Engineer, you will play a crucial role in designing, implementing, and maintaining data pipelines, ETL processes, and data storage solutions on GCP. Your work will contribute to the company's data-driven decision-making and analytics initiatives.\n",
      "\n",
      "Job Description:\n",
      "\n",
      "Role : Data Engineer (GCP)\n",
      "Location : #Bangalore, #Chennai , #Hyderabad\n",
      "Mandatory Skills : GCP (Google cloud platform), Hadoop/ Teradata / SQL, Python/ Pyspark\n",
      "Notice Period : Immediate to 15 Days\n",
      "Experience : 5 to 10 years\n",
      "\n",
      "Qualifications\n",
      "Data modeling, data engineering, and ETL skills\n",
      "Data warehousing and data analytics skills\n",
      "Experience in building data pipelines and data engineering solutions\n",
      "Experience with Python, SQL, and NoSQL databases\n",
      "Understanding of Big Data platforms Hadoop or Teradata\n",
      "Experience with cloud-based environments with GCP\n",
      "Excellent problem-solving and troubleshooting skills\n",
      "Bachelor's or higher degree in Computer Science or related field\n",
      "Experience with agile methodologies is a plus\n",
      "\n",
      "#dataengineer #GCP #Googlecloudplatform #Hadoop #Teradata #Python #Pyspark\n",
      "\n",
      "@Meedenlabs @Prabhu Nadar @Kaviya Nayak @Kishore Kumar D @Sanidhya Gowda @Venkat B\n",
      "Company Name : Jupitice Justice Technologies\n",
      "Job Title    : Data Scientist - Machine Learning Frameworks\n",
      "Location     : Chandigarh, Chandigarh, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-scientist-machine-learning-frameworks-at-jupitice-justice-technologies-3722422065?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=Ce3AGPs3JUQPCTdKjNdwRw%3D%3D&position=15&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Data Scientist\n",
      "\n",
      "Requirements :\n",
      "\n",
      "Strong understanding of linear algebra, optimisation, probability, statistics\n",
      "Experience in the data science methodology from exploratory data analysis, feature engineering, model selection, deployment of the model at scale and model evaluation\n",
      "Experience in deploying NLP architectures and LLM in production\n",
      "Understanding of latest NLP architectures like transformers is good to have\n",
      "Experience in adversarial attacks/robustness of DNN is good to have\n",
      "Experience with Python Web Framework (Django, Flask), Analytics and Machine Learning frameworks like Tensorflow/Keras/Pytorch/NLTK.\n",
      "Experience in designing ML Use Cases.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Use effective text representations techniques to transform natural language into useful features.\n",
      "\n",
      "(ref:hirist.com)\n",
      "Company Name : Response Informatics\n",
      "Job Title    : Data Scientist - Artificial Intelligence/Machine Learning\n",
      "Location     : Kolkata, West Bengal, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-scientist-artificial-intelligence-machine-learning-at-response-informatics-3721922006?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=2qJGonK4cbR13Zw4gEjohw%3D%3D&position=16&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Description\n",
      "\n",
      "Experience in statistical modeling, machine learning, data mining, unstructured data analytics in corporate or academic research environments.\n",
      "Experience in AI/ML, GenAI, LLM\n",
      "Stochastic models, Bayesian modeling, Classification models, Cluster analysis, Neural Network, non-parametric methods,\n",
      "Multivariate statistics, Time Series analysis, Regression models, Deep Learning.\n",
      "Experience in NLP, NLU, NLG\n",
      "Experience in NLP tools such as Word2Vec, TextBlob, NLTK, SpaCy, Gensim, CoreNLP, BERT, GloVe etc.\n",
      "Experience in AWS / Azure / GCP / hyper scale implementation.\n",
      "Good programming skills in Python or R.\n",
      "Experience in Tensorflow, Tesseract will be an advantage.\n",
      "Knowledge in Big Data shall be an advantage.\n",
      "Expertise in delivering end to end analytical solutions covering multiple technologies & tools to multiple business problems.\n",
      "Ability to co-ordinate multiple teams with analytical or non-analytical objectives.\n",
      "Partner closely with project managers to deconstruct business problems of the client, develop data models and algorithms that deliver meaningful insights.\n",
      "Critical thinking ability to work in ambiguous situations with unstructured problems.\n",
      "Strong analytical skills with the ability to collect, organize, review significant amounts of information.\n",
      "Excellent presentation skills.\n",
      "Excellent written and verbal communication skills and ability to work in a team.\n",
      "Outstanding analytical and problem-solving skills.\n",
      "\n",
      "(ref:hirist.com)\n",
      "Company Name : Quantium\n",
      "Job Title    : IND (New) Data Engineer - wiq\n",
      "Location     : Hyderabad, Telangana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/ind-new-data-engineer-wiq-at-quantium-3675415506?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=nhuBsEy%2FaUxkNqMx%2FCYwuw%3D%3D&position=20&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Role Summary\n",
      "\n",
      "As an Engineer you will be responsible for developing readable, maintainable and efficient code to realise user stories that deliver the product road-map, and for ensuring that code is properly tested.\n",
      "\n",
      "Through active participation in Scrum ceremonies, you will contribute to the product road-map and collaborate with other Engineers and Analysts to assist in defining the technical direction for the product. You will also work with support teams to ensure the product's smooth operation.\n",
      "\n",
      "Key Responsibilities\n",
      "\n",
      "Produce Quality Code\n",
      "Code follows team standards, is structured to ensure readability and maintainability and goes through review smoothly, even for complex changes\n",
      "Designs respect best practices and are favourably reviewed by peers\n",
      "Critical paths through code are covered by appropriate tests\n",
      "Data updates are monitored and complete within SLA\n",
      "Operate at a High Level of Productivity\n",
      "Estimates are consistently ‘challenging, but realistic’\n",
      "Most tasks are delivered within estimate\n",
      "Complex or larger tasks are delivered with minimal assistance\n",
      "Squad Collaboration\n",
      "Sprint goals are consistently achieved\n",
      "Demonstrate commitment to continuous improvement of squad activities\n",
      "\n",
      "Key activities\n",
      "\n",
      "Write polished code, aligned to team standards, including appropriate unit / integration tests\n",
      "Review code and test cases produced by others, to ensure changes satisfy the associated business requirement, follow best practices, and integrate with the existing code-base\n",
      "Provide constructive feedback to other team members on quality of code and test cases\n",
      "Troubleshoot production problems and raise / prioritise bug tickets to resolve any issues\n",
      "Proactively monitor system health and act to report / resolve any issues\n",
      "Provide out of hours support for periodic ETL processes, ensuring SLAs are met\n",
      "Contribute to backlog refinement sessions, helping to break down each epic into a collection of smaller user stories that will deliver the overall feature\n",
      "Contribute to work breakdown sessions to define the technical tasks required to implement each user story\n",
      "Contribute to sprint planning sessions, ensuring the team takes a 'realistic but challenging' amount of work into each sprint and each team member will be productively occupied\n",
      "Contribute to the team’s daily stand-up, highlighting any delays or impediments to progress and proposing mitigation for those issues\n",
      "Contribute to sprint review and sprint retro sessions, to maintain a culture of continuous improvement within the team\n",
      "\n",
      "Experience And Education Required\n",
      "\n",
      "2+ years' experience developing at scale applications using Scala\n",
      "Proven experience manipulating large data-sets using Spark\n",
      "Solid foundation in functional programming and data structures\n",
      "Values delivering high-quality, peer-reviewed, well-tested code\n",
      "Awareness of DevOps functions and appetite to contribute to CI / CD pipelines\n",
      "Experience working with source control tools (GIT preferred) with good understanding of branching / merging strategies\n",
      "Bachelor’s degree in Computer Science, Information Technology or a related discipline\n",
      "Comfortable working in a fast moving, agile development environment\n",
      "Excellent problem solving / analytical skills\n",
      "Good written / verbal communication skills\n",
      "Commercially aware, with the ability to work with a diverse range of stakeholders\n",
      "\n",
      "What does success look like?\n",
      "\n",
      "New features delivered within estimate, with minimal defects and no material errors\n",
      "System availability and data updates complete within SLA\n",
      "All user queries and support incidents handled within the team\n",
      "\n",
      "We recognize that it takes time to adapt to a new role and to build relationships with key contacts in the business. We expect a successful employee to be on the following trajectory:\n",
      "\n",
      "After 1 month you should be:\n",
      "embedded within your squad, engaging easily with other team members and raising constructive feedback on the team's work\n",
      "working autonomously on simple tasks / user stories\n",
      "After 3 months, you should be:\n",
      "self-sufficient on all but the most complex tasks / user stories, delivering good quality code in line with other team members' estimations\n",
      "sufficiently aware of the business domain and product road-map to be active in team meetings and contribute towards the product road-map\n",
      "building a network of contacts across Engineering and your business vertical\n",
      "After 6 months, you should have:\n",
      "fully effective in your role within the team\n",
      "capable of mentoring / on-boarding new starters into more junior roles\n",
      "\n",
      "Key Business Capabilities Required\n",
      "\n",
      "Development – Applying technical expertise to construct a solution to meet specific objectives or requirements\n",
      "Fast-Fail / Agile Testing – Ability to try something, get fast feedback, and then rapidly inspect and adapt for great effectiveness\n",
      "Implementation Phase Design – Ability to plan the execution of an application, idea, model, design, specification, standard, algorithm, or policy\n",
      "High Level Design – Ability to define an overview of an entire system, identifying the main components that would be developed for the product/technology and their interfaces\n",
      "Release Management – Ability to oversee the testing, deployment and support of software or product releases\n",
      "\n",
      "Key People And Leadership Capabilities Required\n",
      "\n",
      "Self-aware - you leverage diversity across people, tasks, client interactions and projects, taking responsibility for self and other\n",
      "Agile and innovative - you possess strong lateral thinking skills and actively develop these in others\n",
      "Achieve and perform - you have exceptional execution skills and are achievement focused\n",
      "Brand advocate - you anticipate and consider brand and cultural impact in decision making\n",
      "Purposeful and aligned - you are able to set clear, tangible objectives which deliver against our strategy\n",
      "Achievement oriented - you effectively facilitate challenging performance related conversations in a timely and appropriate manner\n",
      "Coach - you demonstrate the ability to coach and develop others while facilitating learning, growth and engagement\n",
      "Company Name : Adobe\n",
      "Job Title    : Sr Data Science Engineer\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/sr-data-science-engineer-at-adobe-3726694558?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=hcwgvhn1krAs98msFnb15w%3D%3D&position=23&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Our Company\n",
      "\n",
      "Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.\n",
      "\n",
      "We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!\n",
      "\n",
      "The AI/ ML Sr Consultant position is a Innovation and Solution incubation role requiring both technical and business/marketing knowledge and skills. AI/ML Sr Consultant will work with multiple stakeholders from 1) Global practice teams 2) Implementation teams 3) Product engineering teams. The responsibilities include but not limited to deep dive into emerging product roadmap, trending customer problems and derive referential deliverables to Implementation teams. The referential deliverables will give the solutions from use cases derived out of research. AI/ML Sr Consultant should be able to pivot the role of early learner and demonstrator of AI and Generative AI capabilities being launched and researched in Adobe. AI/ML Sr Consultant should be able to research on product capabilities and apply customer emerging needs /Usecase as a consumption lens to define path breaking and futuristic solutions. Accumulate and dissipate knowledge in forms of play books, white papers, create proof of technology. In addition, consultant help each client architect and implement best in class web analytic setup throughout their websites and applications, perform quality checks to ensure that the implementation work has been completed successfully, and diagnose and solve technical issues when they arise. He/she will also be responsible to contribute to overall digital strategy and derive and setup Analytics product integration with other products to solve key business use-cadeveses. It is an evangelist role with constant focus on research, learning and demonstrating capabilities and enabling teams.\n",
      "\n",
      "What you'll do\n",
      "\n",
      "Work with internal product and engineering teams learning the AI and Generative AI features , functionalities being developed on Digital experience products .\n",
      "Asses and understand the emerging LLM that are suitable for consulting and co-pilot needs.\n",
      "Define the path forward for fine tuning the LLM models for the Consulting services usecase.\n",
      "Define and help build the APIs of various products to deliver AI/ML based solutions to other product and solution teams.\n",
      "Help understand and clean datasets for networks, help interpret network outputs and make them comprehensible to understand for other teams.\n",
      "Create networks that curate (add/generate) media (text today and media tomorrow).\n",
      "Build models for legal predictive analytics, natural language understanding, forecasting and anomaly detection.\n",
      "Understand the problems that go into building these networks and innovate solutions to mitigate these problems.\n",
      "Support the development of proofs of concept to demonstrate the application of AI/ML capabilities in solving customer problems in collaboration with product and other development teams.\n",
      "Conduct experiments to evaluate the performance of different machine learning models and algorithms.\n",
      "Design, develop, and deploy large-scale machine learning solutions that can handle huge volumes of data with high performance and accuracy which includes data exploration, data preparation, feature engineering, model selection, and hyperparameter tuning\n",
      "Understand different media types (images, audio, video. Etc) and build networks that extract information and summary from media.\n",
      "Build a deep understanding of usage and patterns in language.\n",
      "Provide statistical input and solutions to help product teams make a better decision.\n",
      "\n",
      "Report on customer trends and deployment performance and identify areas that we can use target using ML/Data science solutions.\n",
      "\n",
      "What You Need To Succeed\n",
      "\n",
      "Must have:\n",
      "\n",
      "8+ yrs. of overall experience working in web analytics or a related field\n",
      "Bachelor's/Master's degree in Computer Science with equivalent work experience\n",
      "Ability to read and implement related academic literature in deep learning, large language models.\n",
      "Fine tune large language models that can generate high-quality text to solve domain specific needs.\n",
      "Hands-on experience working with large language models like GPT, LLAMA, BERT, or Transformer-based architectures.\n",
      "Implement end-to-end machine learning pipelines, including data preprocessing, model training, evaluation, and deployment.\n",
      "Continuously research and stay up to date with recent advancements in NLP and large language models, applying novel techniques and methodologies to improve our models.\n",
      "Conduct experiments and benchmarking to assess the performance of various model architectures and optimize hyperparameters.\n",
      "Troubleshoot and resolve any issues arising during model training and deployment.\n",
      "Solid understanding of the production of machine learning workflow.\n",
      "Build an ongoing understanding of current state art of NLU (Natural languages understanding) architectures, methods and processes.\n",
      "Strong technical knowledge of Predictive Modeling, Feature Engineering/Scaling, Model Evaluation, and Model Selection.\n",
      "Experience in deploying AI applications powered by complex deep learning models in the field of NLP.\n",
      "Python, Java, LP, Machine Learning, and Deep Learning (TensorFlow and Pytorch).\n",
      "Proficient in shell scripting and automation tools.\n",
      "\n",
      "Special consideration given for:\n",
      "\n",
      "Experience in fine tuning and customizing the LLM.\n",
      "Experience in prompt engineering.\n",
      "Strong technical knowledge of Predictive Modeling, Feature Engineering/Scaling, Model Evaluation, and Model Selection.\n",
      "Experience in deploying AI applications powered by complex deep learning models in the field of NLP.\n",
      "Python, Java, LP, Machine Learning, and Deep Learning (TensorFlow and Pytorch).\n",
      "\n",
      "Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.\n",
      "\n",
      "Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.\n",
      "\n",
      "Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.\n",
      "Company Name : Sanofi\n",
      "Job Title    : Lead Data Engineer\n",
      "Location     : Hyderabad, Telangana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/lead-data-engineer-at-sanofi-3730084286?refId=N%2F912mAtGHRqEVoRCmVEWw%3D%3D&trackingId=BJzhFo9bcCSI6NduJJNEWA%3D%3D&position=24&pageNum=1&trk=public_jobs_jserp-result_search-card\n",
      "Description  : About Sanofi:\n",
      "\n",
      "We are an innovative global healthcare company, driven by one purpose: we chase the miracles of science to improve people’s lives. Our team, across some 100 countries, is dedicated to transforming the practice of medicine by working to turn the impossible into the possible. We provide potentially life-changing treatment options and life-saving vaccine protection to millions of people globally, while putting sustainability and social responsibility at the center of our ambitions.\n",
      "\n",
      "Sanofi has recently embarked into a vast and ambitious digital transformation program. A cornerstone of this roadmap is the acceleration of its data transformation and of the adoption of artificial intelligence (AI) and machine learning (ML) solutions that will accelerate Manufacturing & Supply performance and help bring drugs and vaccines to patients faster, to improve health and save lives.\n",
      "\n",
      "Who You Are:\n",
      "\n",
      "You are a dynamic Data Engineer interested in challenging the status quo to design and develop globally scalable solutions that are needed by Sanofi’s advanced analytic, AI and ML initiatives for the betterment of our global patients and customers. You are a valued influencer and leader who has contributed to making key datasets available to data scientists, analysts, and consumers throughout the enterprise to meet vital business use needs. You have a keen eye for improvement opportunities while continuing to fully comply with all data quality, security, and governance standards.\n",
      "\n",
      "Our vision for digital, data analytics and AI\n",
      "\n",
      "Join us on our journey in enabling Sanofi’s Digital Transformation through becoming an AI first organization. This means:\n",
      "\n",
      "AI Factory - Versatile Teams Operating in Cross Functional Pods: Utilizing digital and data resources to develop AI products, bringing data management, AI and product development skills to products, programs and projects to create an agile, fulfilling and meaningful work environment.\n",
      "Leading Edge Tech Stack: Experience building products that will be deployed globally on a leading-edge tech stack.\n",
      "World Class Mentorship and Training: Working with renowned leaders and academics in machine learning to further develop your skillsets\n",
      "\n",
      "There are multiple vacancies across our Digital profiles and NA region. Further assessments will be completed to determine specific function and level of hired candidates.\n",
      "\n",
      "Job Highlights:\n",
      "\n",
      "Propose and establish technical designs to meet business and technical requirements\n",
      "Develop and maintain data engineering solutions based on requirements and design specifications using appropriate tools and technologies\n",
      "Create data pipelines / ETL pipelines and optimize performance\n",
      "Test and validate developed solution to ensure it meets requirements\n",
      "Coach other members of data engineering teams on workflows, technical topics, pipeline management\n",
      "Create design and development documentation based on standards for knowledge transfer, training, and maintenance\n",
      "Work with business and products teams to understand requirements, and translate them into technical needs\n",
      "Adhere to and promote to best practices and standards for code management, automated testing, and deployments\n",
      "Leverage existing or create new standard data pipelines within Sanofi to bring value through business use cases\n",
      "Develop automated tests for CI/CD pipelines\n",
      "Gather/organize large & complex data assets, and perform relevant analysis\n",
      "Conduct peer reviews for quality, consistency, and rigor for production level solution\n",
      "Actively contribute to Data Engineering community and define leading practices and frameworks\n",
      "Communicate results and findings in a clear, structured manner to stakeholders\n",
      "Remains up to date on the company’s standards, industry practices and emerging technologies\n",
      "\n",
      "Key Functional Requirements & Qualifications:\n",
      "\n",
      "Experience working cross-functional teams to solve complex data architecture and engineering problems\n",
      "Demonstrated ability to learn new data and software engineering technologies in short amount of time\n",
      "Good understanding of agile/scrum development processes and concepts\n",
      "Able to work in a fast-paced, constantly evolving environment and manage multiple priorities\n",
      "Strong technical analysis and problem-solving skills related to data and technology solutions\n",
      "Excellent written, verbal, and interpersonal skills with ability to communicate ideas, concepts and solutions to peers and leaders\n",
      "Pragmatic and capable of solving complex issues, with technical intuition and attention to detail\n",
      "Service-oriented, flexible, and approachable team player\n",
      "Fluent in English (Other languages a plus)\n",
      "\n",
      "Key Technical Requirements & Qualifications:\n",
      "\n",
      "Bachelor’s Degree or equivalent in Computer Science, Engineering, or relevant field\n",
      "6+ years of experience in data engineering, integration, data warehousing, business intelligence, business analytics, or comparable role with relevant technologies and tools, such as Spark/Scala, Informatica/IICS/Dbt\n",
      "Understanding of data structures and algorithms\n",
      "Working knowledge of scripting languages (Python, Shell scripting)\n",
      "Experience in cloud-based data platforms (Snowflake is a plus)\n",
      "Experience with job scheduling and orchestration (Airflow is a plus)\n",
      "Good knowledge of SQL and relational databases technologies/concepts\n",
      "Experience working with data models and query tuning\n",
      "\n",
      "Nice to haves:\n",
      "\n",
      "Experience working in life sciences/pharmaceutical industry is a plus\n",
      "Familiarity with data ingestion through batch, near real-time, and streaming environments\n",
      "Familiarity with data warehouse concepts and architectures (data mesh a plus)\n",
      "Familiarity with Source Code Management Tools (GitHub a plus)\n",
      "\n",
      "At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.\n",
      "Company Name : Berkadia\n",
      "Job Title    : Manager, Data Engineer\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/manager-data-engineer-at-berkadia-3727814308?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=EgVqzNhWdywc7yBcNr0ZIg%3D%3D&position=3&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Title: Manager, Data Engineering\n",
      "\n",
      "Line of Business: Innovation Technology\n",
      "\n",
      "Employment Type: Permanent\n",
      "\n",
      "Work Classification: Full Time\n",
      "\n",
      "____________________\n",
      "\n",
      "Position Summary\n",
      "\n",
      "As the Manager, Data Engineering, you will be responsible for building and delivering scalable data solutions to develop and grow Berkadia’s Polaris platform.\n",
      "\n",
      "In this role, you will partner with a world class team of architects, data scientists, data engineers and others to grow data and information capabilities that will be used to inform business decisions, product optimizations, and product design.\n",
      "\n",
      "The Manager, Data Engineering will be responsible for developing an overarching data governance framework to effectively and successfully manage large amounts of data.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Primary responsibilities include the following:\n",
      "\n",
      "Lead, manage and provide technical direction and guidance to a team of data engineers by empowering team members to deliver results\n",
      "Develop software engineering best practices, guidelines, procedures, repeatable and scalable frameworks\n",
      "Develop an overarching data governance framework to successfully manage large amounts of data, ensuring compliance with regulations while maintaining data integrity and accessibility\n",
      "Partner with peers in research, development, product, data science and others to plan and execute a comprehensive data roadmap\n",
      "\n",
      "Supervisory Responsibilities\n",
      "\n",
      "Directly supervises non-supervisory employee(s). Carries out supervisory responsibilities in accordance with the organization's policies and applicable laws.\n",
      "\n",
      "Lead teams in setting goals that align with company’s plans and vision and communicate them throughout the company\n",
      "Organize workflow and ensure that employees understand their responsibilities and delegated tasks\n",
      "Monitor employee productivity and provide constructive feedback and coaching\n",
      "Act as a communication conduit between upper management and employees\n",
      "Prepare, submit, and review weekly engineering metrics\n",
      "Collaborate with upper management and employees and assist employees with career development\n",
      "Hire and train new employees on the data architecture, tools, and framework\n",
      "Ensure adherence to legal and company policies and procedures and undertake disciplinary actions if the need arises\n",
      "\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "Qualifications\n",
      "\n",
      "Qualifications to perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the experience required.\n",
      "\n",
      "Strong Software Engineering and coding skills with significant experience in Data Platforms and core AWS services.\n",
      "Expertise in Data Integration tools such as SQL, Spark, Scala, Python, Data Bricks, Airflow, R, Machine Learning\n",
      "Passionate about developing quality solutions\n",
      "Strong experience in system analysis, data modeling, data architecture, and data warehousing tools such as DynamoDB, PostgreSQL, RDS, Oracle, Redshift and MPP/Cloud Data Warehouses such as Snowflake\n",
      "Experience with Agile methodologies\n",
      "Hands on experience with various Business Intelligence reporting tools such as PowerBI and Tableau\n",
      "Strong attention to detail and ability to manage multiple projects and stakeholders\n",
      "Ability to produce quality results in an evolving, fast-paced environment\n",
      "\n",
      "Preferred Education\n",
      "\n",
      "Bachelor’s degree or equivalent\n",
      "\n",
      "Preferred Previous Experience\n",
      "\n",
      "Seven to ten years prior experience in a similar position.\n",
      "\n",
      "Berkadia, as an equal opportunity employer, celebrates our employees’ unique differences, which we believe drives personal and company-wide innovation and creates a people-first culture where your career can take the long view. To achieve these goals, we are committed to the full inclusion of all qualified individuals, without regard to race, religion, age, color, national origin, gender, sexual orientation, gender identity or expression, marital status, domestic partner status, military and veteran status, disability, pregnancy, parental status, genetic information, political affiliation, or any other status protected by federal, state and local laws.\n",
      "\n",
      "In keeping with our commitment, Berkadia takes the necessary steps to provide a workplace free from harassment and discrimination, as well as access and reasonable accommodations for individuals with disabilities. If you require reasonable accommodation to take part in the interview process, please contact talentacquisition@berkadia.com.\n",
      "\n",
      "You have rights under Federal and State employment laws. No question in this Application is intended to elicit information in violation of any such law, nor will any information obtained in response to any question be used in violation of any such law. If you apply for this role, you are acknowledging Berkadia's Application Policy and Berkadia's Privacy Policy. Please click the following links for more information about: EEOC, Employee Rights under the FMLA, EPPA.\n",
      "Company Name : NEC Software Solutions\n",
      "Job Title    : Data Engineer / Senior Data Engineer - GCP, Bigquery\n",
      "Location     : Mumbai, Maharashtra, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-senior-data-engineer-gcp-bigquery-at-nec-software-solutions-3728272266?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=KcJzR8hWd8nCGvk6rwfjug%3D%3D&position=5&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Company Description\n",
      "\n",
      "NEC Software Solutions (India)\n",
      "\n",
      "On 1st July 2021, Rave Technologies became NEC Software Solutions India. This change brought us under the global NEC Corporation brand. We are proud to be part of an organisation with 122 years of experience in evolution with technology and innovation.\n",
      "\n",
      "We have more than 30 years of experience in providing end to end IT services across the globe and have earned a reputation for delighting our customers by consistently surpassing expectations and helping them deliver robust, market-ready software products that meet the highest standards of engineering and user experience. Supported by more than 1300 exceptionally talented manpower, we are a hub for offshore support and technology services.\n",
      "\n",
      "We work with diverse industry verticals which include publishing, media, financial services, retail, healthcare and technology companies around the world. Our customers range from two-person startups to $bn listed companies.\n",
      "\n",
      "For more information, visit at www.necsws.com/india.\n",
      "\n",
      "About NEC Corporation\n",
      "\n",
      "NEC Corporation is a Japanese multinational information technology and electronics company, headquartered in Tokyo, Japan. It is recognised as a ‘Top 50 Innovative Company’ globally and the NEC Group globally provides “Solutions for Society” that promote the safety, security, fairness and equality of society. Their main goal is to help create a safer society with their innovations in technologies.\n",
      "\n",
      "NEC Corporation has established itself as a leader in the integration of IT and network technologies while promoting the brand statement of “Orchestrating a brighter world.” NEC enables businesses and communities to adapt to rapid changes taking place in both society and the market as it provides for the social values of safety, security, fairness and efficiency to promote a more sustainable world where everyone has the chance to reach their full potential.\n",
      "\n",
      "For more information, visit NEC at https://www.nec.com.\n",
      "\n",
      "Job Description\n",
      "\n",
      "Experience: 6 - 10 Yrs\n",
      "\n",
      "Have experience with Data Fusion or Equivalent, Big Query or Equivalent, SQL server, scripting in Java/Python that works well in GCP products, and their respective practices. Python experience is a plus.\n",
      "Develop data ETL pipelines that meets both the functional and non-functional requirements, including performance, scalability, availability, reliability and security.\n",
      "Have experience with writing code in Java, in order to work on data extracts that require cleanup.\n",
      "Have a working knowledge of XML, JSON and other forms of data streaming artifacts and related technologies in a Java/Python environment.\n",
      "Have strong written and verbal communication skills\n",
      "Able to multi task on various streams of the entire data process.\n",
      "\n",
      "Additional Information\n",
      "\n",
      "Good Communication Skills required.\n",
      "Company Name : Esri\n",
      "Job Title    : Product Engineer II - Geospatial Data Science\n",
      "Location     : New Delhi, Delhi, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/product-engineer-ii-geospatial-data-science-at-esri-3726102463?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=cGdFcqqnGqUkB01zwyNJow%3D%3D&position=7&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Overview\n",
      "\n",
      "Are you passionate about applying data science and artificial intelligence to solve some of the world’s biggest challenges? So are we! Esri is the world leader in geographic information systems (GIS) and developer of ArcGIS, the leading mapping and analytics software used in 75 percent of Fortune 500 companies. At the Esri R&D Center-New Delhi, we are applying cutting-edge AI and deep learning techniques to revolutionize geospatial analysis and derive insight from imagery and location data.\n",
      "\n",
      "Our team develops tools, APIs, and AI models for geospatial analysts and data scientists, enabling them to leverage the latest research in spatial data science, AI, and geospatial deep learning. Our product engineers provide a strong technical voice in the product development process and use the best tools available to build highly reliable, sustained, and evolutionary software.\n",
      "\n",
      "As a Product Engineer, you will help us design, build, and deliver geospatial AI tools, models, and libraries. This work will include performing, documenting, and teaching a wide variety of technical tasks, developing best practices, creating tutorials and documentation, and gathering requirements. If you are passionate about geospatial AI, have a deep understanding of the product and customer needs, and communicate effectively via writing and presentations, this is the place to be!\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Collaborate with data scientists and engineers on the design, development, testing, documentation and release of tools, APIs and pretrained models for geospatial AI\n",
      "Develop and implement test plans and test cases, write test code, verify code changes, bug fixes for the relevant and related products to maintain product quality\n",
      "Troubleshoot and triage customer issues, analyse user feedback to identify areas for improvement\n",
      "Develop samples, tutorials, documentation, blog posts and presentation of product features\n",
      "Develop pre-trained geospatial AI models for imagery, 3D datasets and text\n",
      "Review and analyse test results; report status on software quality and stability; and certify software, SDK, and AI model quality\n",
      "\n",
      "Requirements\n",
      "\n",
      "2 to 5 years of industry experience in software testing, development, or technical writing\n",
      "Proven data science and AI skills with Python, PyTorch and Jupyter Notebooks\n",
      "Experience developing and implementing test plans and test automation framework\n",
      "Fundamental understanding of machine learning and deep learning\n",
      "Excellent problem-solving and analytical skills\n",
      "Effective project management, time management, and organizational skills\n",
      "Excellent technical writing skills and experience authoring samples, blog posts, and product documentation\n",
      "Bachelor's in GIS, geography, engineering, computer science, math, or related fields\n",
      "\n",
      "Recommended Qualifications\n",
      "\n",
      "Master's in GIS, geography, engineering, computer science, math, or related fields\n",
      "Strong knowledge of software QA methodologies, tools, and processes\n",
      "Experience working in an Agile/Scrum development process\n",
      "Familiarity with ArcGIS suite of products and concepts of GIS\n",
      "Experience with remote sensing and multispectral image analysis\n",
      "\n",
      "About Esri\n",
      "\n",
      "Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.\n",
      "\n",
      "Esri is an equal opportunity employer (EOE), and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.\n",
      "\n",
      "If you need a reasonable accommodation for any part of the employment process, please email askcareers@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.\n",
      "Company Name : Gemini\n",
      "Job Title    : Staff Data Engineer, Crypto Core\n",
      "Location     : Gurgaon, Haryana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/staff-data-engineer-crypto-core-at-gemini-3730082137?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=TfWa55ShHTyMjkYcrZcTNQ%3D%3D&position=9&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : About The Company\n",
      "\n",
      "Gemini is a global crypto and Web3 platform founded by Tyler Winklevoss and Cameron Winklevoss in 2014. Gemini offers a wide range of crypto products and services for individuals and institutions in over 70 countries.\n",
      "\n",
      "Our flagship product, the Gemini Exchange, was built to be a compliant and secure platform to buy, sell, and store crypto. Our suite of retail products includes ActiveTrader, a high-performance platform for advanced traders. Gemini also offers the Gemini Credit Card providing real-time crypto rewards, the Gemini dollar (GUSD), a U.S. dollar-backed stablecoin, and Gemini Staking, allowing users to securely stake their tokens on-chain and receive rewards. Nifty Gateway, Gemini's NFT platform, is the world's premier marketplace for NFTs and digital art.\n",
      "\n",
      "Gemini customers also have access to a wide range of institutional products tailor-made for high-net-worth individuals, asset and wealth managers, and hedge funds and liquidity providers seeking exposure to crypto. Customers looking to place large orders can use Gemini eOTC, a fully-electronic over-the-counter trading platform built for high-value bulk orders. For wealth management professionals, we offer a unique destination for their clients’ crypto portfolios from a single platform, and we enable fully electronic clearing and settlement of off-exchange crypto trades.\n",
      "\n",
      "The Department: Crypto Core\n",
      "\n",
      "The Role: Staff Data Engineer\n",
      "\n",
      "You are considered a leader on our data engineering team, dealing with ambiguous problems with limited guidance. Your solutions are developed with the team's long term goals and overall architecture in perspective. By driving data engineering best practices, you set standards, coach and mentor data engineers and analysts, and help them along their career goals at Gemini. Communicating your insights with leaders across the organization is paramount to success.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Focused on technical decision making, leading work/projects that affects one or more complex systems and mission-critical areas\n",
      "Consistently deliver code that sets the standard for quality and maintainability\n",
      "Write highly insightful, comprehensive code reviews\n",
      "Design, architect and implement best-in-class Data Warehousing and reporting solutions\n",
      "Lead and participate in design discussions and meetings\n",
      "Can successfully plan and execute projects involving multiple developers and complex requirements, prioritizing strategically\n",
      "Identify, define, and solve strategic problems, thinking holistically about the whole system\n",
      "Mentor data engineers and analysts\n",
      "Design, automate, build, and launch scalable, efficient and reliable data pipelines into production using Python\n",
      "Build real-time data and reporting solutions\n",
      "Design, build and enhance dimensional models for Data Warehouse and BI solutions\n",
      "Research new tools and technologies to improve existing processes\n",
      "Develop new systems and tools to enable the teams to consume and understand data more intuitively\n",
      "Partner with engineers, project managers, and analysts to deliver insights to the business\n",
      "Perform root cause analysis and resolve production and data issues\n",
      "\n",
      "Minimum Qualifications\n",
      "\n",
      "7+ years experience in data engineering with data warehouse technologies\n",
      "7+ years experience in custom ETL design, implementation and maintenance\n",
      "7+ years experience with schema design and dimensional data modeling\n",
      "Experience building real-time data solutions and processes\n",
      "Advanced skills with Python and SQL are a must\n",
      "Experience and expertise in Databricks, Spark, Hadoop, etc.\n",
      "Experience with one or more MPP databases (Redshift, Bigquery, Snowflake, etc.)\n",
      "Experience with one or more ETL tools (Informatica, Pentaho, SSIS, Alooma, etc.)\n",
      "Strong computer science fundamentals including data structures and algorithms\n",
      "Strong software engineering skills in any server side language, preferable Python\n",
      "Experienced in working collaboratively across different teams and departments\n",
      "Strong technical and business communication skills\n",
      "\n",
      "Preferred Qualifications\n",
      "\n",
      "Kafka, Spark, HDFS/S3, Messaging, machine learning, text analysis, Cloud computing (especially AWS) experience is a plus\n",
      "Experience with orchestration frameworks like Airflow and continuous integration and deployment\n",
      "Knowledge and experience of blockchain, financial markets, banking or exchanges\n",
      "Knowledge of working with BI applications (Tableau/Looker/Power BI, etc)\n",
      "Knowledge and experience of financial markets, banking or exchanges\n",
      "Web development skills with HTML, CSS, or JavaScript\n",
      "\n",
      "It Pays to Work Here\n",
      "\n",
      "The Compensation & Benefits Package For This Role Includes\n",
      "\n",
      "Competitive base salary\n",
      "Benefits\n",
      "Discretionary annual bonus\n",
      "\n",
      "At Gemini, we strive to build diverse teams that reflect the people we want to empower through our products, and we are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. Equal Opportunity is the Law, and Gemini is proud to be an equal opportunity workplace. If you have a specific need that requires accommodation, please let a member of the People Team know.\n",
      "Company Name : Looper Development Services\n",
      "Job Title    : Data Engineer\n",
      "Location     : Mumbai, Maharashtra, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-at-looper-development-services-3730086232?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=G1bqQ%2BpQ4GoCk2RVL%2BqkWA%3D%3D&position=10&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Description:\n",
      "Position Overview:\n",
      "As a Data Engineer specializing in Google Cloud Platform (GCP), you will play a crucial role in designing, developing, and maintaining data infrastructure and pipelines that support our data-driven initiatives. You will work closely with data scientists, analysts, and other cross-functional teams to ensure data availability, quality, and reliability.\n",
      "Key Responsibilities:\n",
      "Data Pipeline Development: Design, build, and maintain scalable data pipelines on GCP using tools such as Google Cloud Dataflow, Apache Beam, and Apache Airflow.\n",
      "Data Integration: Integrate data from various sources into the GCP environment, ensuring data consistency, accuracy, and reliability.\n",
      "Data Warehousing: Implement and manage data warehousing solutions using Google BigQuery, optimizing for performance and cost efficiency.\n",
      "Data Transformation: Transform raw data into usable formats for analysis and reporting, leveraging tools like Google Data Prep and Dataflow.\n",
      "Data Quality Assurance: Implement data quality checks and monitoring to ensure data integrity and reliability.\n",
      "Performance Optimization: Continuously monitor and optimize data pipelines and ETL processes for efficiency and scalability.\n",
      "Security and Compliance: Ensure that data is handled securely and in compliance with industry standards and regulations.\n",
      "Collaboration: Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver data solutions that meet business needs.\n",
      "Documentation: Maintain comprehensive documentation of data pipelines, processes, and best practices.\n",
      "Qualifications:\n",
      "Bachelor's degree in computer science, data engineering, or a related field (Master's degree preferred).\n",
      "Proven experience as a Data Engineer with a focus on Google Cloud Platform (GCP).\n",
      "Strong proficiency in GCP services such as BigQuery, Dataflow, Pub/Sub, and Cloud Storage.\n",
      "Experience with data modeling, ETL processes, and data warehousing concepts.\n",
      "Proficiency in programming languages such as Python.\n",
      "Knowledge of version control systems (e.g., Git) and CI/CD pipelines (e.g., Google Cloud Build, Bitbucket).\n",
      "Familiarity with data integration and data quality tools.\n",
      "Strong problem-solving skills and attention to detail.\n",
      "Excellent communication and collaboration skills.\n",
      "GCP certification(s) a plus.\n",
      "Company Name : Gemini\n",
      "Job Title    : Senior Data Engineer, Crypto Core\n",
      "Location     : Gurgaon, Haryana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/senior-data-engineer-crypto-core-at-gemini-3730083113?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=vdPE7nvkVzMftEpOfjQCSA%3D%3D&position=11&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : About The Company\n",
      "\n",
      "Gemini is a global crypto and Web3 platform founded by Tyler Winklevoss and Cameron Winklevoss in 2014. Gemini offers a wide range of crypto products and services for individuals and institutions in over 70 countries.\n",
      "\n",
      "Our flagship product, the Gemini Exchange, was built to be a compliant and secure platform to buy, sell, and store crypto. Our suite of retail products includes ActiveTrader, a high-performance platform for advanced traders. Gemini also offers the Gemini Credit Card providing real-time crypto rewards, the Gemini dollar (GUSD), a U.S. dollar-backed stablecoin, and Gemini Staking, allowing users to securely stake their tokens on-chain and receive rewards. Nifty Gateway, Gemini's NFT platform, is the world's premier marketplace for NFTs and digital art.\n",
      "\n",
      "Gemini customers also have access to a wide range of institutional products tailor-made for high-net-worth individuals, asset and wealth managers, and hedge funds and liquidity providers seeking exposure to crypto. Customers looking to place large orders can use Gemini eOTC, a fully-electronic over-the-counter trading platform built for high-value bulk orders. For wealth management professionals, we offer a unique destination for their clients’ crypto portfolios from a single platform, and we enable fully electronic clearing and settlement of off-exchange crypto trades.\n",
      "\n",
      "The Department: Crypto Core\n",
      "\n",
      "The Role: Senior Data Engineer\n",
      "\n",
      "As a member of our data engineering team, you'll deliver high quality work while solving challenges that impact the whole or part of the team's data architecture. You'll update yourself with recent advances in data analysis and computation while providing solutions for large-scale applications aligning with the team's long term goals. Your work will help resolve complex problems with identifying root causes, documenting the solutions, and implementing operational excellence in mind (e.g., data auditing, validation, automation, maintainability). Communicating your insights with leaders across the organization is paramount to success.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Design, architect and implement best-in-class Data Warehousing and reporting solutions\n",
      "Lead and participate in design discussions and meetings\n",
      "Mentor data engineers and analysts\n",
      "Design, automate, build, and launch scalable, efficient and reliable data pipelines into production using Python\n",
      "Build real-time data and reporting solutions\n",
      "Design, build and enhance dimensional models for Data Warehouse and BI solutions\n",
      "Research new tools and technologies to improve existing processes\n",
      "Develop new systems and tools to enable the teams to consume and understand data more intuitively\n",
      "Partner with engineers, project managers, and analysts to deliver insights to the business\n",
      "Perform root cause analysis and resolve production and data issues\n",
      "Create test plans, test scripts and perform data validation\n",
      "Tune SQL queries, reports and ETL pipelines\n",
      "Build and maintain data dictionary and process documentation\n",
      "\n",
      "Minimum Qualifications\n",
      "\n",
      "5+ years experience in data engineering with data warehouse technologies\n",
      "5+ years experience in custom ETL design, implementation and maintenance\n",
      "5+ years experience with schema design and dimensional data modeling\n",
      "Experience building real-time data solutions and processes\n",
      "Advanced skills with Python and SQL are a must\n",
      "Experience with one or more MPP databases (Redshift, Bigquery, Snowflake, etc)\n",
      "Experience with one or more ETL frameworks (Custom, DBT, Databricks, etc)\n",
      "Strong computer science fundamentals including data structures and algorithms\n",
      "Strong software engineering skills in any server side language, preferable Python\n",
      "Experienced in working collaboratively across different teams and departments\n",
      "Strong technical and business communication\n",
      "\n",
      "Preferred Qualifications\n",
      "\n",
      "Spark, HDFS/S3, Messaging, Cloud computing (especially AWS) experience is a plus\n",
      "Experience with orchestration frameworks like Airflow and continuous integration and deployment\n",
      "Knowledge and experience of blockchain, financial markets, banking or exchanges\n",
      "Knowledge of working with BI applications (Tableau/Looker/Power BI, etc)\n",
      "Web development skills with HTML, CSS, or JavaScript\n",
      "\n",
      "It Pays to Work Here\n",
      "\n",
      "The Compensation & Benefits Package For This Role Includes\n",
      "\n",
      "Competitive base salary\n",
      "Benefits\n",
      "Discretionary annual bonus\n",
      "\n",
      "At Gemini, we strive to build diverse teams that reflect the people we want to empower through our products, and we are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. Equal Opportunity is the Law, and Gemini is proud to be an equal opportunity workplace. If you have a specific need that requires accommodation, please let a member of the People Team know.\n",
      "Company Name : GlobalFoundries\n",
      "Job Title    : Data Engineer - Machine Learning/Data Science\n",
      "Location     : Bangalore Urban, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-machine-learning-data-science-at-globalfoundries-3696940494?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=usKKLoSe%2FBJ9jNdTLEP16A%3D%3D&position=13&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : About GLOBALFOUNDRIES\n",
      "\n",
      "GlobalFoundries is a leading full-service semiconductor foundry providing a unique combination of design, development, and fabrication services to some of the world’s most inspired technology companies. With a global manufacturing footprint spanning three continents, GlobalFoundries makes possible the technologies and systems that transform industries and give customers the power to shape their markets. For more information, visit www.gf.com.\n",
      "\n",
      "Introduction\n",
      "\n",
      "The Data Science team in GLOBALFOUNDRIES has a primary mission of delivering data engineering, advanced analytics, and machine learning applications to improve business operations in any of our business units. We are involved in the entire application lifecycle from concept to deployment.\n",
      "\n",
      "The successful candidate will help architect and build data flows for advanced analytics and machine learning applications, as well as build custom tools to facilitate the speedy development and release of the applications.\n",
      "\n",
      "Essential Responsibilities\n",
      "Build tools to automate and improve development and release processes and deploy Machine Learning (ML) to large production environments.\n",
      "Utilize Versioning Repository tools, Continuous Integration Frameworks, Application Containerization, Automation Deployment, Code Quality and Code Security Scanning tools.\n",
      "Design, build, and maintain efficient, reusable, and tested code in Python and other applicable languages and library tools.\n",
      "Design modern data pipeline architectures and build tooling to efficiently tackle Big Data projects in a multi-cloud environment.\n",
      "Able to handle multiple projects.\n",
      "Present project status to peers and the leadership team as needed, collaborate across organizational boundaries.\n",
      "Required Qualifications\n",
      "B.S. in Computer Science, Software Engineering, or equivalent field with 2-4 years industrial experience, or M.S. with 1-3 years' experience.\n",
      "Experience with full stack development\n",
      "Understanding of REST APIs, JSON data format\n",
      "Experience with ML services in AWS ecosystem\n",
      "Experience with the deployment of big data ETL pipelines in the cloud, e.g. PySpark\n",
      "Experience with of SQL and NoSQL databases, Python, Docker containers\n",
      "Exposure to and/or understanding of ML tools/libraries such as: TensorFlow/Keras, PyTorch, Pandas\n",
      "Understanding of advanced data analytics and machine learning\n",
      "Prior experience architecting end-to-end pipeline for ML and Analytics using AWS services.\n",
      "Understanding of MLOps tools and flow\n",
      "Preferred Qualifications\n",
      "B.S. in Computer Science, Software Engineering, or equivalent field with 4-5 years industrial experience, or M.S. with 2-4 years’ experience.\n",
      "Experience in project management, structured problem solving, and structured risk assessment and mitigation.\n",
      "Experience deploying advanced data analytics and machine learning applications.\n",
      "Understanding of AWS Well Architected Framework (6 pillars)\n",
      "Experience mentoring junior engineers / interns.\n",
      "AWS certifications (Associate Solution Architect\n",
      "GlobalFoundries is an equal opportunity employer, cultivating a diverse and inclusive workforce. We believe having a multicultural workplace enhances productivity, efficiency and innovation whilst our employees feel truly respected, valued and heard.\n",
      "\n",
      "As an affirmative employer, all qualified applicants are considered for employment regardless of age, ethnicity, marital status, citizenship, race, religion, political affiliation, gender, sexual orientation and medical and/or physical abilities.\n",
      "\n",
      "All offers of employment with GlobalFoundries are conditioned upon the successful completion of background checks, medical screenings as applicable and subject to the respective local laws and regulations.\n",
      "\n",
      "To ensure that we maintain a safe and healthy workplace for our GlobalFoundries employees, please note that offered candidates who have applied for jobs in India will have to be fully vaccinated prior to their targeted start date. For new hires, the appointment is contingent upon the provision of a copy of their COVID-19 vaccination document, subject to any written request for medical or religious accommodation.\n",
      "\n",
      "Information about our benefits you can find here: https://gf.com/about-us/careers/opportunities-asia\n",
      "Company Name : Berkadia\n",
      "Job Title    : Senior Data Engineer\n",
      "Location     : Hyderabad, Telangana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/senior-data-engineer-at-berkadia-3612402134?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=Ik9knU1szv1Enc2azvfnrA%3D%3D&position=15&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : To Be Completed By Manager\n",
      "\n",
      "Shift: 3:00pm to 12:00am\n",
      "\n",
      "Job Title: Senior Data Engineer\n",
      "\n",
      "Line of Business: Innovation Technology\n",
      "\n",
      "Employment Type: Permanent\n",
      "\n",
      "Work Classification: Full Time\n",
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "Position Summary\n",
      "\n",
      "As a member of the Data Pipeline team you’ll be at the center of building our platform that enables us to redefine the Commercial Real Estate industry. We’re building a data pipeline that merges the tested design of data warehousing and the latest big data technologies. You will be designing and building data projects while securing core data elements.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      "Essential Duties (Primary Responsibilities) include the following:\n",
      "\n",
      "Research new technology and share knowledge with team and peers\n",
      "Design, implement and release data applications in AWS using big data technologies\n",
      "Coordinate development efforts across the organization\n",
      "Influence team in development standards and processes\n",
      "Teach and mentor peers\n",
      "Other duties as assigned\n",
      "\n",
      "Supervisory Responsibilities\n",
      "\n",
      "This job has no supervisory responsibilities.\n",
      "\n",
      "_________________________________________________________________________________________________\n",
      "\n",
      "Qualifications\n",
      "\n",
      "Qualifications to perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the experience required:\n",
      "\n",
      "5 -8years of hands on Apache Spark experience (PySpark preferred)\n",
      "hands on Business Intelligence / Data Warehousing experience\n",
      "1-2 years of experience building high-performance algorithms in scalable languages such as Scala, Python and R\n",
      "Excellent interpersonal, verbal and written communication skills\n",
      "Experience mentoring junior engineers and performing code reviews\n",
      "Strong logical, analytical, problem solving and reporting skills\n",
      "Familiarity with Agile principles and methodologies\n",
      "AWS Elastic Map Reduce (EMR) experience\n",
      "Able to use version control (git) and other build, packaging & release management tools\n",
      "Passionate about developing quality products\n",
      "\n",
      "Preferred Education\n",
      "\n",
      "Bachelor’s degree or equivalent\n",
      "\n",
      "Berkadia, as an equal opportunity employer, celebrates our employees’ unique differences, which we believe drives personal and company-wide innovation and creates a people-first culture where your career can take the long view. To achieve these goals, we are committed to the full inclusion of all qualified individuals, without regard to race, religion, age, color, national origin, gender, sexual orientation, gender identity or expression, marital status, domestic partner status, military and veteran status, disability, pregnancy, parental status, genetic information, political affiliation, or any other status protected by federal, state and local laws.\n",
      "\n",
      "In keeping with our commitment, Berkadia takes the necessary steps to provide a workplace free from harassment and discrimination, as well as access and reasonable accommodations for individuals with disabilities. If you require reasonable accommodation to take part in the interview process, please contact talentacquisition@berkadia.com.\n",
      "\n",
      "You have rights under Federal and State employment laws. No question in this Application is intended to elicit information in violation of any such law, nor will any information obtained in response to any question be used in violation of any such law. If you apply for this role, you are acknowledging Berkadia's Application Policy and Berkadia's Privacy Policy. Please click the following links for more information about: EEOC, Employee Rights under the FMLA, EPPA.\n",
      "Company Name : Greenlight\n",
      "Job Title    : Data Analytics Engineer\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-analytics-engineer-at-greenlight-3727925571?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=JvvhGRsTyEWdPmTr9IzTCA%3D%3D&position=16&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Greenlight is the leading family fintech company on a mission to help parents raise financially smart kids. We proudly serve more than 6 million parents and kids with our award-winning banking app for families. With Greenlight, parents can automate allowance, manage chores, set flexible spend controls, and invest for their family’s future. Kids and teens learn to earn, save, spend wisely, and invest.\n",
      "\n",
      "At Greenlight, we believe every child should have the opportunity to become financially healthy and happy. It’s no small task, and that’s why we leap out of bed every morning to come to work. Because creating a better, brighter future for the next generation depends on it.\n",
      "\n",
      "As an Analytics Engineer, you will play a crucial role in developing and implementing data models and analytics solutions using DBT and Snowflake. Your primary focus will be on leveraging these technologies to design and build scalable data pipelines, perform complex data transformations, and develop analytical models that contribute to our risk management and re-platforming strategies. You will collaborate closely with cross-functional teams, including data scientists, analysts, and software engineers, to ensure the successful delivery of robust and reliable solutions. You will be responsible for change management and data governance of re-platforming efforts and of translating the existing data models to the new platform.\n",
      "\n",
      "What you will be doing:\n",
      "Utilize DBT and Snowflake to design, develop, and maintain scalable and efficient data pipelines for analytics purposes.\n",
      "Collaborate with stakeholders to understand business requirements and translate them into technical specifications and data models.\n",
      "Work with cross functional teams on data requirements, quality assurance, and data infrastructure needs on product initiatives\n",
      "Perform complex data transformations, including data cleaning, aggregation, and enrichment, to ensure the availability of high-quality data for analysis.\n",
      "Develop and maintain analytical models and algorithms to support data assessments, portfolio analysis, and predictive modeling.\n",
      "Optimize and fine-tune data pipelines and models to improve performance, accuracy, and reliability.\n",
      "Conduct data profiling, analysis, and validation to identify data quality issues and implement appropriate solutions.\n",
      "Monitor and troubleshoot data pipelines and analytics workflows to ensure smooth and efficient operations.\n",
      "\n",
      "What you should bring:\n",
      "Bachelor's degree in Computer Science, Data Science, Statistics, or a related field. Advanced degree preferred.\n",
      "Prior experience working as a Data Engineer, Analytics Engineer, or similar role preferably in the fintech or financial services industry.\n",
      "Proficiency in implementing data solutions using DBT (Data Build Tool) and Snowflake is essential.\n",
      "Strong knowledge of SQL and expertise in data modeling, data warehousing, and ETL processes.\n",
      "Experience with Python or other programming languages for data manipulation and scripting.\n",
      "Familiarity with risk management concepts and analytics methodologies in the fintech domain.\n",
      "Demonstrated ability to collaborate effectively with cross-functional teams and communicate complex technical concepts to non-technical stakeholders.\n",
      "Strong problem-solving skills and attention to detail, with a focus on delivering high-quality, reliable solutions.\n",
      "Experience with version control systems (e.g., Git) and agile development methodologies is a plus.\n",
      "Familiarity with other data engineering tools, such as Apache Airflow, is a plus.\n",
      "\n",
      "Who we are:\n",
      "It takes a special team to aim for a never-been-done-before mission like ours. We’re looking for people who love working together because they know it makes us stronger, people who look to others and ask, “How can I help?” and then “How can we make this even better?” If you’re ready to roll up your sleeves and help parents raise a financially smart generation, apply to join our team.\n",
      "\n",
      "Greenlight is an equal opportunity employer and will not discriminate against any employee or applicant based on age, race, color, national origin, gender, gender identity or expression, sexual orientation, religion, physical or mental disability, medical condition (including pregnancy, childbirth, or a medical condition related to pregnancy or childbirth), genetic information, marital status, veteran status, or any other characteristic protected by federal, state or local law.\n",
      "Company Name : AXA XL\n",
      "Job Title    : Assistant Scientist, Business Data Services\n",
      "Location     : Gurgaon, Haryana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/assistant-scientist-business-data-services-at-axa-xl-3726268052?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=tXFDpYv2K03UMUbLGOxbfQ%3D%3D&position=17&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : AXA XL offers risk transfer and risk management solutions to clients globally. We offer worldwide capacity, flexible underwriting solutions, a wide variety of client-focused loss prevention services, and a team-based account management approach.\n",
      "\n",
      "AXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities. This data should not only be high quality, but also actionable – enabling AXA XL’s executive leadership team to maximize benefits and facilitate sustained competitive advantage. Our Innovation, Data, and Analytics (IDA) organization is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model – disrupting the insurance market.\n",
      "\n",
      "This role is part of the Business Data Services team within the Digital Data Dev Division and will be responsible for different aspects of Data Product development lifecycle activities, including but not limited to Data Production Support, business stakeholders engagement for usage & and problem resolutions, quality engineering and platform/data product rollouts, performance stability & reliability.\n",
      "\n",
      "DISCOVER your opportunity\n",
      "\n",
      "What will your essential responsibilities include?\n",
      "Technical and functional support for Artificial Intelligence (AI) based solutions in cloud and big data-based production environments.\n",
      "Monitor daily data load process (ETL data pipeline) and work towards the resolution of any issue occurring during the process run.\n",
      "Analyze and mitigate risks about Data solution delivery timelines, quality, stability, and performance.\n",
      "Identify and execute opportunities (as prioritized) for automation and continuous improvement for in-scope products/projects/services across the Digital Data Dev division.\n",
      "Participate in efforts to identify root causes and collaborate within IDA team(s) to deliver solutions.\n",
      "Provide top-class production support and ensure data solutions service level commitments (SLAs) are met or exceeded.\n",
      "Demonstrate proactive communication and relationship with Business users and Product teams - Development, Technology, Support, and Delivery Teams.\n",
      "Execute and guide the execution of tasks to provide quality service to end users through the Incident Management process.\n",
      "Work in the “Follow the Sun” support model providing cross-team support coverage across Digital Data Dev division responsibilities.\n",
      "Grow and maintain data solutions knowledge through documentation.\n",
      "Ensure that all policies, standards, and best practices are followed and kept up to date.\n",
      "Continually improve the health and performance of data solutions through identifying problems and solutions.\n",
      "Work with various teams to implement automated recovery steps, and document RCA and/or preventative measures for recurring issues/problems.\n",
      "Achieve & and maintain the highest business customer confidence and net promoter score (NPS).\n",
      "You will report to Lead for AI (Artificial Intelligence) Production Support– Business Data Services.\n",
      "\n",
      "We’re looking for someone who has these abilities and skills:\n",
      "\n",
      "Required Skills And Abilities\n",
      "A minimum of an Undergraduate University Degree in Computer Science or related fields.\n",
      "Relevant experience in providing production support for AI-based Solutions/Products.\n",
      "Experience with SQL, HIVE, ADLS, SQL DW Analytics, and Databricks notebook.\n",
      "Understanding of DataOps, and AGILE methodologies.\n",
      "Basic understanding of AI concepts, Python.\n",
      "Any Certification/training in Data Science, Artificial Intelligence, and Machine Learning will be preferred.\n",
      "Extensive experience in Data data-focused roles (analytics, specialist, or engineer) and one or more areas of Data Management & and support.\n",
      "Experience with any monitoring tool like Dynatrace.\n",
      "Ability to handle different types of user inquiries provide guidance and execute on next steps for troubleshooting and resolution.\n",
      "Distinctive problem-solving and analytical skills combined with strong business acumen.\n",
      "Data engineering background or working experience with ETL, Big data platform (ADLS / Data Bricks).\n",
      "Desired Skills And Abilities\n",
      "Demonstrates a level of experience/ability to influence, and understand business problems in technical terminology.\n",
      "Robust interpersonal skills and relationship building and able to liaise with staff at all levels in the organization.\n",
      "Excellent writing skills, with the ability to create clear requirements, specifications, and documentation for data systems.\n",
      "Additional certifications such as ITIL, AGILE, etc.\n",
      "FIND your future\n",
      "\n",
      "AXA XL, the P&C and specialty risk division of AXA, is known for solving complex risks. For mid-sized companies, multinationals, and even some inspirational individuals we don’t just provide re/insurance, we reinvent it.\n",
      "\n",
      "How? By combining a comprehensive and efficient capital platform, data-driven insights, leading technology, and the best talent in an agile and inclusive workspace, empowered to deliver top client service across all our lines of business − property, casualty, professional, financial lines, and specialty.\n",
      "\n",
      "With an innovative and flexible approach to risk solutions, we partner with those who move the world forward.\n",
      "\n",
      "Learn more at axaxl.com\n",
      "\n",
      "Inclusion & Diversity\n",
      "\n",
      "AXA XL is committed to equal employment opportunity and will consider applicants regardless of gender, sexual orientation, age, ethnicity and origins, marital status, religion, disability, or any other protected characteristic.\n",
      "\n",
      "At AXA XL, we know that an inclusive culture and a diverse workforce enable business growth and are critical to our success. That’s why we have made a strategic commitment to attract, develop, advance, and retain the most diverse workforce possible, and create an inclusive culture where everyone can bring their full selves to work and can reach their highest potential. It’s about helping one another — and our business — to move forward and succeed.\n",
      "Five Business Resource Groups focused on gender, LGBTQ+, ethnicity and origins, disability, and inclusion with 20 Chapters around the globe\n",
      "Robust support for Flexible Working Arrangements\n",
      "Enhanced family-friendly leave benefits\n",
      "Named to the Diversity Best Practices Index\n",
      "Signatory to the UK Women in Finance Charter\n",
      "Learn more at axaxl.com/about-us/inclusion-and-diversity. AXA XL is an Equal Opportunity Employer.\n",
      "\n",
      "Sustainability\n",
      "\n",
      "At AXA XL, Sustainability is integral to our business strategy. In an ever-changing world, AXA XL protects what matters most for our clients and communities. We know that sustainability is at the root of a more resilient future. Our 2023-26 Sustainability strategy, called “Roots of resilience”, focuses on protecting natural ecosystems, addressing climate change, and embedding sustainable practices across our operations.\n",
      "\n",
      "Flexible Work Eligible\n",
      "\n",
      "Flexible Work Schedule\n",
      "\n",
      "AXA XL is an Equal Opportunity Employer.\n",
      "\n",
      "Location\n",
      "\n",
      "IN-HR-Silokhera Gurgaon\n",
      "\n",
      "Job Field\n",
      "\n",
      "Operations\n",
      "\n",
      "Schedule\n",
      "\n",
      "Full-time\n",
      "\n",
      "Job Type\n",
      "\n",
      "Standard\n",
      "Company Name : TEKGENCE INC\n",
      "Job Title    : Python Data Testing engineer - 5 to 7 years- Bengaluru - Immediate Joiners only\n",
      "Location     : Bengaluru, Karnataka, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/python-data-testing-engineer-5-to-7-years-bengaluru-immediate-joiners-only-at-tekgence-inc-3721195039?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=wrc4WVtJLvdLXqpfhULq3w%3D%3D&position=18&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Title : Python Data Testing engineer\n",
      "Location: Bengaluru\n",
      "Qualification : BE, BTech, MTech\n",
      "Experience : 5 to 7 Years\n",
      "\n",
      "JAutomation, Data testing(Kubernetes,APIs with grpcurl and grpc_cli commands), DB testing, python\n",
      "Company Name : V Support Solutions\n",
      "Job Title    : ETL and data engineer 5 - 6 Years\n",
      "Location     : Coimbatore, Tamil Nadu, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/etl-and-data-engineer-5-6-years-at-v-support-solutions-3726561169?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=9BgVHhdCcZJUhW8v%2BtHK9g%3D%3D&position=19&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Description:\n",
      "Bachelor's degree in Computer Science, Information Technology, or a related field.\n",
      "5-6 years of overall IT experience.\n",
      "3-4 years of hands-on experience in ETL processes in live projects.\n",
      "Proficiency in Python for automation and scripting.\n",
      "Strong understanding of cloud migration concepts and strategies.\n",
      "Experience with one or more cloud platforms (AWS, Azure, Google Cloud).\n",
      "Problem-solving skills and the ability to adapt to changing project requirements.\n",
      "Excellent communication and collaboration skills.\n",
      "Certifications in cloud computing (e.g., AWS Certified Solutions Architect, Microsoft Azure Administrator) are a plus.\n",
      "Company Name : Quarks\n",
      "Job Title    : Data Engineer - ETL/Data Pipeline\n",
      "Location     : Gurugram, Haryana, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-etl-data-pipeline-at-quarks-3726294999?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=MKxM64IakDbCwRAwgsZCgw%3D%3D&position=21&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Responsibilities (Must Haves)\n",
      "\n",
      "Design, build and maintain ETL/ELT pipelines.\n",
      "Implement data monitoring, including basic data quality checks.\n",
      "Transform raw data into scalable, performant data models that would be consumed by data analysts and data scientists.\n",
      "Design, build and update foundational analytics data models that simplify analyses across the products.\n",
      "Implement best practices to ensure high quality, robust data.\n",
      "Experience developing orchestration/scheduling jobs using Degree in a computer science, software engineering\n",
      "Minimum of 8+ years (5+ with advanced degree) experience working in an engineering role\n",
      "Strong communication skills, both written and verbal\n",
      "Proficient with transactional Python and while not required analytical Python too\n",
      "Advanced SQL ability including dimensional modeling and data model design\n",
      "Advanced in data principles, data architecture & data modeling\n",
      "Experience with cloud platforms (preferably AWS) and Spark\n",
      "Experience with ML engineering is a plus\n",
      "Analytical problem solving skills\n",
      "Previous experience working with product/user data\n",
      "\n",
      "(ref:hirist.com)\n",
      "Company Name : Avalara\n",
      "Job Title    : Data Engineer\n",
      "Location     : Pune, Maharashtra, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-at-avalara-3726243886?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=mgIoQXWr9xkI6HxkIMrQ3w%3D%3D&position=22&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Job Summary:\n",
      "This Senior Software Enginner in Data Engineering will be responsible for design, code & implement end to end solutions using a combination of Snowflake, Python, Talend and AWS along with BI tools like Tableau/Power Bi for data validation, data cleaning, investigating data issues, report creation and automation.\n",
      "\n",
      "Responsibilities:\n",
      "Job Duties:\n",
      "Work closely with IT, Marketing, Sales, and Finance to align metrics and reporting.\n",
      "Use quantitative skills to troubleshoot technical issues with platforms, data discrepancies, alerts , etc.\n",
      "Identify ETL jobs failures and work with IT team to address.\n",
      "Design and development of reporting views in SQL server/Snowflake to optimize reporting and dashboards.\n",
      "Design, Develop and manage Tableau/Power Bi dashboards.\n",
      "Understand, monitor, and enhance ETLs to accurately measure existing KPIs, while bringing an analytical mindset to propose and implement newer and more relevant KPIs.\n",
      "Provide support to stakeholders including answering inquires, investigating data issues, and creating custom visualization and analysis to answer business questions.\n",
      "Design and develop robust data structures and highly reliable data pipelines.\n",
      "Understand and document technical specifications, process flows, and source-to-target mappings.\n",
      "Provide support/consultation/analysis for management reporting requests.\n",
      "\n",
      "Qualifications:\n",
      "Qualifications:\n",
      "Bachelor's degree in Computer Science, Informatics, Business, or other related quantitative field or equivalent experience required.\n",
      "Overall experience should be around 5-7 years in Data Engineering field.\n",
      "Minimum of 4-5 years building data solutions utilizing Tableau/Power Bi\n",
      "Minimum of 4-5 years’ experience in SQL and ETL code.\n",
      "Good analytical skills with excellent knowledge of SQL.\n",
      "Experience with data modelling and data warehouse design principles and implementation\n",
      "as well as familiarity with data analytics and data mining.\n",
      "Working knowledge of Salesforce.com .\n",
      "Ability to work independently in a dynamic, fast-paced environment with minimal supervision\n",
      "Familiarity with Snowflake, Python, Talend and AWS is desired.\n",
      "Willingness to learn and adapt to new tools.\n",
      "Experience in working in Onsite - Offshore environment.\n",
      "Soft Skills:\n",
      "Excellent communication\n",
      "Creative thinking, problem-solving, and great logical reasoning\n",
      "Excellent logical and analytical skills\n",
      "Excellent Organizational & Managerial skills\n",
      "Deals with conflict constructively and is a skilled communicator\n",
      "Team player\n",
      "Company Name : NEC Software Solutions (India)\n",
      "Job Title    : Data Engineer / Senior Data Engineer - GCP, Bigquery\n",
      "Location     : Mumbai, Maharashtra, India\n",
      "Website URL  : https://in.linkedin.com/jobs/view/data-engineer-senior-data-engineer-gcp-bigquery-at-nec-software-solutions-india-3728285039?refId=o4Qi5A6AiMzYMp1phhn8ew%3D%3D&trackingId=RI0JUKjDjxLv3rXMQzPgUw%3D%3D&position=23&pageNum=2&trk=public_jobs_jserp-result_search-card\n",
      "Description  : Company Description\n",
      "\n",
      "NEC Software Solutions (India)\n",
      "\n",
      "On 1st July 2021, Rave Technologies became NEC Software Solutions India. This change brought us under the global NEC Corporation brand. We are proud to be part of an organisation with 122 years of experience in evolution with technology and innovation.\n",
      "\n",
      "We have more than 30 years of experience in providing end to end IT services across the globe and have earned a reputation for delighting our customers by consistently surpassing expectations and helping them deliver robust, market-ready software products that meet the highest standards of engineering and user experience. Supported by more than 1300 exceptionally talented manpower, we are a hub for offshore support and technology services.\n",
      "\n",
      "We work with diverse industry verticals which include publishing, media, financial services, retail, healthcare and technology companies around the world. Our customers range from two-person startups to $bn listed companies.\n",
      "\n",
      "For more information, visit at www.necsws.com/india.\n",
      "\n",
      "About NEC Corporation\n",
      "\n",
      "NEC Corporation is a Japanese multinational information technology and electronics company, headquartered in Tokyo, Japan. It is recognised as a ‘Top 50 Innovative Company’ globally and the NEC Group globally provides “Solutions for Society” that promote the safety, security, fairness and equality of society. Their main goal is to help create a safer society with their innovations in technologies.\n",
      "\n",
      "NEC Corporation has established itself as a leader in the integration of IT and network technologies while promoting the brand statement of “Orchestrating a brighter world.” NEC enables businesses and communities to adapt to rapid changes taking place in both society and the market as it provides for the social values of safety, security, fairness and efficiency to promote a more sustainable world where everyone has the chance to reach their full potential.\n",
      "\n",
      "For more information, visit NEC at https://www.nec.com.\n",
      "\n",
      "Job Description\n",
      "\n",
      "Experience: 6 - 10 Yrs\n",
      "\n",
      "Have experience with Data Fusion or Equivalent, Big Query or Equivalent, SQL server, scripting in Java/Python that works well in GCP products, and their respective practices. Python experience is a plus.\n",
      "Develop data ETL pipelines that meets both the functional and non-functional requirements, including performance, scalability, availability, reliability and security.\n",
      "Have experience with writing code in Java, in order to work on data extracts that require cleanup.\n",
      "Have a working knowledge of XML, JSON and other forms of data streaming artifacts and related technologies in a Java/Python environment.\n",
      "Have strong written and verbal communication skills\n",
      "Able to multi task on various streams of the entire data process.\n",
      "Additional Information\n"
     ]
    }
   ],
   "source": [
    "l = len(df['Company Name'])\n",
    "for i in range(0,l):\n",
    "    print(f\"Company Name : {df.iloc[i,0]}\")\n",
    "    print(f\"Job Title    : {df.iloc[i,1]}\")\n",
    "    print(f\"Location     : {df.iloc[i,2]}\")\n",
    "    print(f\"Website URL  : {df.iloc[i,3]}\")\n",
    "    print(f\"Description  : {df.iloc[i,4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
